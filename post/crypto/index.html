<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Cuong Sai">

  
  
  
    
  
  <meta name="description" content="==&gt; Bài viết chưa hoàn thành, hiện đang cập nhật
Trong machine learning tồn tại định lý “không có bữa trưa miễn phí” (No free lunch theorem), tức là không tồn tại một thuật toán mà luôn tốt và cho hiệu suất cao cho mọi ứng dụng và trên mọi tập dữ liệu, vì các thuật toán machiner learning thường dựa trên một tập các tham số (hyperparameter) hoặc dựa trên một giả thiết nhất định nào đó về phân bố dữ liệu.">

  
  <link rel="alternate" hreflang="en-us" href="/post/crypto/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128408660-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-128408660-5', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu47efca792e1e7000f9078d7b8f1dac48_31011_32x32_fill_lanczos_center_2.PNG">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu47efca792e1e7000f9078d7b8f1dac48_31011_192x192_fill_lanczos_center_2.PNG">

  <link rel="canonical" href="/post/crypto/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Data Science">
  <meta property="og:url" content="/post/crypto/">
  <meta property="og:title" content="Phương pháp Ensemble Learning trong Machine Learning: Boosting, Bagging và Stacking (Sử dụng R code) | Data Science">
  <meta property="og:description" content="==&gt; Bài viết chưa hoàn thành, hiện đang cập nhật
Trong machine learning tồn tại định lý “không có bữa trưa miễn phí” (No free lunch theorem), tức là không tồn tại một thuật toán mà luôn tốt và cho hiệu suất cao cho mọi ứng dụng và trên mọi tập dữ liệu, vì các thuật toán machiner learning thường dựa trên một tập các tham số (hyperparameter) hoặc dựa trên một giả thiết nhất định nào đó về phân bố dữ liệu."><meta property="og:image" content="/post/crypto/featured.png">
  <meta property="twitter:image" content="/post/crypto/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-08-23T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-08-23T18:45:46&#43;04:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/crypto/"
  },
  "headline": "Phương pháp Ensemble Learning trong Machine Learning: Boosting, Bagging và Stacking (Sử dụng R code)",
  
  "image": [
    "/post/crypto/featured.png"
  ],
  
  "datePublished": "2020-08-23T00:00:00Z",
  "dateModified": "2020-08-23T18:45:46+04:00",
  
  "author": {
    "@type": "Person",
    "name": "Cuong Sai"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Data Science",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/icon_hu47efca792e1e7000f9078d7b8f1dac48_31011_192x192_fill_lanczos_center_2.PNG"
    }
  },
  "description": "==\u0026gt; Bài viết chưa hoàn thành, hiện đang cập nhật\nTrong machine learning tồn tại định lý “không có bữa trưa miễn phí” (No free lunch theorem), tức là không tồn tại một thuật toán mà luôn tốt và cho hiệu suất cao cho mọi ứng dụng và trên mọi tập dữ liệu, vì các thuật toán machiner learning thường dựa trên một tập các tham số (hyperparameter) hoặc dựa trên một giả thiết nhất định nào đó về phân bố dữ liệu."
}
</script>

  

  


  


  





<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    });
    </script>
    <script async type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

  <title>Phương pháp Ensemble Learning trong Machine Learning: Boosting, Bagging và Stacking (Sử dụng R code) | Data Science</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class=" ">

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Data Science</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Data Science</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Tutorials</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#gallery"><span>Gallery</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>



  <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Phương pháp Ensemble Learning trong Machine Learning: Boosting, Bagging và Stacking (Sử dụng R code)</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Aug 23, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    18 min read
  </span>
  

  
  
  
  <span class="middot-divider"></span>
  <a href="/post/crypto/#disqus_thread"></a>
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/r/">R</a></span>
  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 720px;">
  <div style="position: relative">
    <img src="/post/crypto/featured_hu439753291bb70f461c14551713424de1_22606_720x0_resize_lanczos_2.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      


<p><code>==&gt; Bài viết chưa hoàn thành, hiện đang cập nhật</code></p>
<p>Trong <code>machine learning</code> tồn tại định lý “không có bữa trưa miễn phí” (<code>No free lunch theorem</code>), tức là không tồn tại một thuật toán mà luôn tốt và cho hiệu suất cao cho mọi ứng dụng và trên mọi tập dữ liệu, vì các thuật toán <code>machiner learning</code> thường dựa trên một tập các tham số (<code>hyperparameter</code>) hoặc dựa trên một giả thiết nhất định nào đó về phân bố dữ liệu. Vì vậy để tìm được những thuật toán phù hợp cho tập <code>dataset</code> của mình có thể các bạn sẽ cần nhiều thời gian để test các thuật toán khác nhau nhằm mục đích tìm ra danh sách một số thuật toán cho kết quả chính xác. Rồi từ đó hiệu chỉnh (<code>tuning</code>) các tham số của các thuật toán này để thu được độ chính xác cao nhất.</p>
<p>Một cách khác có thể sử dụng để tăng độ chính xác trên tập <code>dataset</code> của bạn là kết hợp (<code>combine</code>) một số mô hình với nhau. Phương pháp này gọi là <code>esemble learning</code>. Ý tưởng của việc <code>combine</code> các mô hình khác nhau xuất phát từ một suy nghĩ hợp lý là: các mô hình khác nhau có khả năng khác nhau, có thể thực hiện tốt nhất các loại công việc khác nhau (<code>subtasks</code>), khi kết hợp các mô hình này với nhau một cách hợp lý thì sẽ tạo thành một mô hình kết hợp (<code>combined model</code>) mạnh có khả năng cải thiện hiệu suât tổng thể và (<code>overall performance</code>) so với việc chỉ dùng các mô hình một cách đơn lẻ.</p>
<p>Các phương pháp <code>Ensemble Learning</code> được chia thành 3 loại sau đây:</p>
<ul>
<li><code>Bagging</code> (đóng bao): Xây dựng một lượng lớn các <code>models</code> (thường là <code>cùng loại</code>) trên những <code>subsamples</code> khác nhau từ tập <code>training dataset</code> một cách song song nhằm đưa ra dự đoán tốt hơn.</li>
<li><code>Boosting</code> (tăng cường): Xây dựng một lượng lớn các <code>models</code> (thường là <code>cùng loại</code>). Tuy nhiên quá trình huấn luyện trong phương pháp này diễn ra tuần tự theo chuỗi (sequence). Trong chuỗi này mỗi <code>model</code> sau sẽ học cách sửa những <code>errors</code> của <code>model</code> trước (hay nói cách khác là dữ liệu mà <code>model</code> trước dự đoán sai).</li>
<li><code>Stacking</code> (Xếp chồng): Xây dựng một số <code>models</code> (thường là <code>khác loại</code>) và một mô hình <code>supervisor model</code>, mô hình này sẽ học cách kết hợp kết quả dự báo của một số mô hình một cách tốt nhất.
Chúng tôi sẽ mô tả từng phương pháp và các chủ đề liên quan dưới đây. (Bổ sung sau)</li>
</ul>
<p><code>Note</code>: <code>Bagging</code> sử dụng những mô hình phức tạp để tối giản những dự đoán trong khi <code>boosting</code> kết hợp những mô hình đơn giản ban đầu nhằm tăng cường (boost) độ phức tạp.</p>
<p>Ở bài này tôi sẽ không giải thích cụ thể từng phương pháp <code>ensemble learning</code> mà tập trung vào hướng dẫn các bạn cách áp dụng chúng vào bài toán cụ thể sử dụng thư viện <code>caret</code> trong R.</p>
<p><strong>Đôi nét vể thư viện <code>caret</code></strong>: Ngôn ngữ <code>R</code> khác biệt bởi số lượng rất lớn các <code>packages</code> chuyên dụng khác nhau cho phép xây dựng các mô hình dự đoán. Tuy nhiên đây cũng chính là khuyết điểm, khi có quá nhiều các gói triển khai <code>machine learning algorithms</code> dưới dạng các
hàm <code>rải rác</code> đòi hỏi ta cần nhiều thời gian để tìm kiếm và nắm vững những đặc trưng về cú pháp cũng như cách sử dụng của từng hàm.Để giải quyết vấn đề này <a href="https://www.linkedin.com/in/max-kuhn-864a9110">Max Kuhn</a> đã xây dựng một giao diện phổ quát cho phép truy cập và sử dụng các <code>machine learning algorithms</code> từ cái gói khác nhau được triển khai trên ngôn ngữ <code>R</code>. Kết quả chính là package <a href="https://cran.r-project.org/web/packages/caret/caret.pdf">caret</a> (viết tắt từ Classification and Regression Training), được công bố đầu tiên vào năm 2008 tại tạp chí phần mềm thống kê (<a href="https://www.jstatsoft.org/article/view/v028i05">Journal of Statistical Software</a>. Gói <code>caret</code> giúp chúng ta tiết kiệm được rất nhiều thời gian trong quá trình phân tích và xây dựng các models. Những đặc trưng cơ bản của package <code>caret</code>:</p>
<ul>
<li><p>sử dụng cú pháp lệnh chung (phổ quát) không phụ thuộc vào cú pháp của các hàm gốc (các hàm triển khai các machine learningalgorithms)</p></li>
<li><p>Tự động tìm kiếm những giá trị tối ưu cho các <code>hyperparameters</code> của mô hình (<code>tuning parameters</code>)</p></li>
<li><p>Có khả năng tổ chức tính toán song song để tăng đáng kể tốc độ quá trình huấn luyện mô hình</p></li>
</ul>
<p>Sử dụng <code>Caret</code> cho phép giải quyết các bài toán chính sau:</p>
<ul>
<li><p>data splitting</p></li>
<li><p>pre-processing</p></li>
<li><p>feature selection</p></li>
<li><p>model tuning using resampling</p></li>
<li><p>variable importance estimation</p></li>
</ul>
<p>Nạp các thư viện cần dùng vào phiên làm việc của <code>R</code> để thực hành:</p>
<pre class="r"><code>library(caret)
library(caretEnsemble) </code></pre>
<p>Nếu chưa cài các thư viện trên thì các bạn dùng lệnh <code>install.packages(.)</code> để cài đặt với tham số đầu vào là tên các thư viện cần cài đặt. Ví dụ:</p>
<pre class="r"><code>install.packages(&quot;caret&quot;)</code></pre>
<p>Kiểm tra số lượng các machine learning algorithms availbe to train in caret:</p>
<pre class="r"><code>carets &lt;- getModelInfo()
carets.names &lt;- names(carets)
length(carets.names)</code></pre>
<pre><code>## [1] 238</code></pre>
<p>Nếu chưa cài các thư viện trên thì các bạn dùng lệnh <code>install.packages(.)</code> để cài đặt với tham số đầu vào là tên các thư viện cần cài đặt. Ví dụ:</p>
<pre class="r"><code>install.packages(&quot;caret&quot;)</code></pre>
<p><strong>Dữ liệu để thực hành</strong></p>
<p>Để thực hành với các phương pháp <code>ensemble learning</code> tôi lựa chọn bài toán phân loại nhị phân (bi classification) với tập dữ liệu <code>ionoshene</code>. Trong bài toán này chúng ta cần dự đoán xem cao tâǹ trả vể từ năng lượng của các hạt trong khí quyển có cấu trúc hay là không. Để tìm hiểu thêm về bài toán này các bạn có thể đọc ở <a href="http://archive.ics.uci.edu/ml/index.php">đây</a>.</p>
<p>Load dữ liệu từ gói <code>mlbench</code></p>
<pre class="r"><code># Load the dataset
library(mlbench)
data(Ionosphere)
dataset &lt;- Ionosphere</code></pre>
<p><strong>Thống kê mô tả (Descriptive statistics)</strong></p>
<p>Kiểm tra kích thước tập dữ liệu:</p>
<pre class="r"><code>dim(dataset)</code></pre>
<pre><code>## [1] 351  35</code></pre>
<p>Kiểm tra cấu trúc của tập dữ liệu:</p>
<pre class="r"><code>str(dataset)</code></pre>
<pre><code>## &#39;data.frame&#39;:    351 obs. of  35 variables:
##  $ V1   : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 1 2 2 ...
##  $ V2   : Factor w/ 1 level &quot;0&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ V3   : num  0.995 1 1 1 1 ...
##  $ V4   : num  -0.0589 -0.1883 -0.0336 -0.4516 -0.024 ...
##  $ V5   : num  0.852 0.93 1 1 0.941 ...
##  $ V6   : num  0.02306 -0.36156 0.00485 1 0.06531 ...
##  $ V7   : num  0.834 -0.109 1 0.712 0.921 ...
##  $ V8   : num  -0.377 -0.936 -0.121 -1 -0.233 ...
##  $ V9   : num  1 1 0.89 0 0.772 ...
##  $ V10  : num  0.0376 -0.0455 0.012 0 -0.164 ...
##  $ V11  : num  0.852 0.509 0.731 0 0.528 ...
##  $ V12  : num  -0.1776 -0.6774 0.0535 0 -0.2028 ...
##  $ V13  : num  0.598 0.344 0.854 0 0.564 ...
##  $ V14  : num  -0.44945 -0.69707 0.00827 0 -0.00712 ...
##  $ V15  : num  0.605 -0.517 0.546 -1 0.344 ...
##  $ V16  : num  -0.38223 -0.97515 0.00299 0.14516 -0.27457 ...
##  $ V17  : num  0.844 0.055 0.838 0.541 0.529 ...
##  $ V18  : num  -0.385 -0.622 -0.136 -0.393 -0.218 ...
##  $ V19  : num  0.582 0.331 0.755 -1 0.451 ...
##  $ V20  : num  -0.3219 -1 -0.0854 -0.5447 -0.1781 ...
##  $ V21  : num  0.5697 -0.1315 0.7089 -0.6997 0.0598 ...
##  $ V22  : num  -0.297 -0.453 -0.275 1 -0.356 ...
##  $ V23  : num  0.3695 -0.1806 0.4339 0 0.0231 ...
##  $ V24  : num  -0.474 -0.357 -0.121 0 -0.529 ...
##  $ V25  : num  0.5681 -0.2033 0.5753 1 0.0329 ...
##  $ V26  : num  -0.512 -0.266 -0.402 0.907 -0.652 ...
##  $ V27  : num  0.411 -0.205 0.59 0.516 0.133 ...
##  $ V28  : num  -0.462 -0.184 -0.221 1 -0.532 ...
##  $ V29  : num  0.2127 -0.1904 0.431 1 0.0243 ...
##  $ V30  : num  -0.341 -0.116 -0.174 -0.201 -0.622 ...
##  $ V31  : num  0.4227 -0.1663 0.6044 0.2568 -0.0571 ...
##  $ V32  : num  -0.5449 -0.0629 -0.2418 1 -0.5957 ...
##  $ V33  : num  0.1864 -0.1374 0.5605 -0.3238 -0.0461 ...
##  $ V34  : num  -0.453 -0.0245 -0.3824 1 -0.657 ...
##  $ Class: Factor w/ 2 levels &quot;bad&quot;,&quot;good&quot;: 2 1 2 1 2 1 2 1 2 1 ...</code></pre>
<p>Hiển thị <code>5</code> hàng dữ liệu đầu tiên:</p>
<pre class="r"><code>head(dataset, 5)</code></pre>
<pre><code>##   V1 V2      V3       V4      V5       V6       V7       V8      V9      V10
## 1  1  0 0.99539 -0.05889 0.85243  0.02306  0.83398 -0.37708 1.00000  0.03760
## 2  1  0 1.00000 -0.18829 0.93035 -0.36156 -0.10868 -0.93597 1.00000 -0.04549
## 3  1  0 1.00000 -0.03365 1.00000  0.00485  1.00000 -0.12062 0.88965  0.01198
## 4  1  0 1.00000 -0.45161 1.00000  1.00000  0.71216 -1.00000 0.00000  0.00000
## 5  1  0 1.00000 -0.02401 0.94140  0.06531  0.92106 -0.23255 0.77152 -0.16399
##       V11      V12     V13      V14      V15      V16     V17      V18      V19
## 1 0.85243 -0.17755 0.59755 -0.44945  0.60536 -0.38223 0.84356 -0.38542  0.58212
## 2 0.50874 -0.67743 0.34432 -0.69707 -0.51685 -0.97515 0.05499 -0.62237  0.33109
## 3 0.73082  0.05346 0.85443  0.00827  0.54591  0.00299 0.83775 -0.13644  0.75535
## 4 0.00000  0.00000 0.00000  0.00000 -1.00000  0.14516 0.54094 -0.39330 -1.00000
## 5 0.52798 -0.20275 0.56409 -0.00712  0.34395 -0.27457 0.52940 -0.21780  0.45107
##        V20      V21      V22      V23      V24      V25      V26      V27
## 1 -0.32192  0.56971 -0.29674  0.36946 -0.47357  0.56811 -0.51171  0.41078
## 2 -1.00000 -0.13151 -0.45300 -0.18056 -0.35734 -0.20332 -0.26569 -0.20468
## 3 -0.08540  0.70887 -0.27502  0.43385 -0.12062  0.57528 -0.40220  0.58984
## 4 -0.54467 -0.69975  1.00000  0.00000  0.00000  1.00000  0.90695  0.51613
## 5 -0.17813  0.05982 -0.35575  0.02309 -0.52879  0.03286 -0.65158  0.13290
##        V28      V29      V30      V31      V32      V33      V34 Class
## 1 -0.46168  0.21266 -0.34090  0.42267 -0.54487  0.18641 -0.45300  good
## 2 -0.18401 -0.19040 -0.11593 -0.16626 -0.06288 -0.13738 -0.02447   bad
## 3 -0.22145  0.43100 -0.17365  0.60436 -0.24180  0.56045 -0.38238  good
## 4  1.00000  1.00000 -0.20099  0.25682  1.00000 -0.32382  1.00000   bad
## 5 -0.53206  0.02431 -0.62197 -0.05707 -0.59573 -0.04608 -0.65697  good</code></pre>
<p>Kiểm tra <code>missing values</code> trong dữ liệu:</p>
<pre class="r"><code>sum(is.na(dataset))</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Kiểm tra phân phối của từng thuộc tính:</p>
<pre class="r"><code>summary(dataset)</code></pre>
<pre><code>##  V1      V2            V3                V4                 V5         
##  0: 38   0:351   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1:313           1st Qu.: 0.4721   1st Qu.:-0.06474   1st Qu.: 0.4127  
##                  Median : 0.8711   Median : 0.01631   Median : 0.8092  
##                  Mean   : 0.6413   Mean   : 0.04437   Mean   : 0.6011  
##                  3rd Qu.: 1.0000   3rd Qu.: 0.19418   3rd Qu.: 1.0000  
##                  Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##        V6                V7                V8                 V9          
##  Min.   :-1.0000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.00000  
##  1st Qu.:-0.0248   1st Qu.: 0.2113   1st Qu.:-0.05484   1st Qu.: 0.08711  
##  Median : 0.0228   Median : 0.7287   Median : 0.01471   Median : 0.68421  
##  Mean   : 0.1159   Mean   : 0.5501   Mean   : 0.11936   Mean   : 0.51185  
##  3rd Qu.: 0.3347   3rd Qu.: 0.9692   3rd Qu.: 0.44567   3rd Qu.: 0.95324  
##  Max.   : 1.0000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.00000  
##       V10                V11                V12                V13         
##  Min.   :-1.00000   Min.   :-1.00000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.04807   1st Qu.: 0.02112   1st Qu.:-0.06527   1st Qu.: 0.0000  
##  Median : 0.01829   Median : 0.66798   Median : 0.02825   Median : 0.6441  
##  Mean   : 0.18135   Mean   : 0.47618   Mean   : 0.15504   Mean   : 0.4008  
##  3rd Qu.: 0.53419   3rd Qu.: 0.95790   3rd Qu.: 0.48237   3rd Qu.: 0.9555  
##  Max.   : 1.00000   Max.   : 1.00000   Max.   : 1.00000   Max.   : 1.0000  
##       V14                V15               V16                V17         
##  Min.   :-1.00000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.07372   1st Qu.: 0.0000   1st Qu.:-0.08170   1st Qu.: 0.0000  
##  Median : 0.03027   Median : 0.6019   Median : 0.00000   Median : 0.5909  
##  Mean   : 0.09341   Mean   : 0.3442   Mean   : 0.07113   Mean   : 0.3819  
##  3rd Qu.: 0.37486   3rd Qu.: 0.9193   3rd Qu.: 0.30897   3rd Qu.: 0.9357  
##  Max.   : 1.00000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V18                 V19               V20                V21         
##  Min.   :-1.000000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.225690   1st Qu.: 0.0000   1st Qu.:-0.23467   1st Qu.: 0.0000  
##  Median : 0.000000   Median : 0.5762   Median : 0.00000   Median : 0.4991  
##  Mean   :-0.003617   Mean   : 0.3594   Mean   :-0.02402   Mean   : 0.3367  
##  3rd Qu.: 0.195285   3rd Qu.: 0.8993   3rd Qu.: 0.13437   3rd Qu.: 0.8949  
##  Max.   : 1.000000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V22                 V23               V24                V25         
##  Min.   :-1.000000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.243870   1st Qu.: 0.0000   1st Qu.:-0.36689   1st Qu.: 0.0000  
##  Median : 0.000000   Median : 0.5318   Median : 0.00000   Median : 0.5539  
##  Mean   : 0.008296   Mean   : 0.3625   Mean   :-0.05741   Mean   : 0.3961  
##  3rd Qu.: 0.188760   3rd Qu.: 0.9112   3rd Qu.: 0.16463   3rd Qu.: 0.9052  
##  Max.   : 1.000000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V26                V27               V28                V29         
##  Min.   :-1.00000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.33239   1st Qu.: 0.2864   1st Qu.:-0.44316   1st Qu.: 0.0000  
##  Median :-0.01505   Median : 0.7082   Median :-0.01769   Median : 0.4966  
##  Mean   :-0.07119   Mean   : 0.5416   Mean   :-0.06954   Mean   : 0.3784  
##  3rd Qu.: 0.15676   3rd Qu.: 0.9999   3rd Qu.: 0.15354   3rd Qu.: 0.8835  
##  Max.   : 1.00000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V30                V31               V32                 V33         
##  Min.   :-1.00000   Min.   :-1.0000   Min.   :-1.000000   Min.   :-1.0000  
##  1st Qu.:-0.23689   1st Qu.: 0.0000   1st Qu.:-0.242595   1st Qu.: 0.0000  
##  Median : 0.00000   Median : 0.4428   Median : 0.000000   Median : 0.4096  
##  Mean   :-0.02791   Mean   : 0.3525   Mean   :-0.003794   Mean   : 0.3494  
##  3rd Qu.: 0.15407   3rd Qu.: 0.8576   3rd Qu.: 0.200120   3rd Qu.: 0.8138  
##  Max.   : 1.00000   Max.   : 1.0000   Max.   : 1.000000   Max.   : 1.0000  
##       V34            Class    
##  Min.   :-1.00000   bad :126  
##  1st Qu.:-0.16535   good:225  
##  Median : 0.00000             
##  Mean   : 0.01448             
##  3rd Qu.: 0.17166             
##  Max.   : 1.00000</code></pre>
<p>Thuộc tính thứ <code>V2</code> chỉ có 1 giá trị là <code>0</code> nên có thể loại bỏ:</p>
<pre class="r"><code>dataset$V2 &lt;- NULL</code></pre>
<p>Chuyển thuộc tính <code>V1</code> từ <code>factor</code> sang <code>numeric</code>:</p>
<pre class="r"><code>dataset$V1 &lt;- as.numeric(as.character(dataset$V1))</code></pre>
<p>Kiểm tra mức độ tương quan (<code>correlation</code>) giữa các thuộc tính (do số lượng thuộc tính lớn nên tôi chỉ hiển thị tương quan giữa 6 thuộc tính đầu):</p>
<pre class="r"><code>cor(dataset[,1:6])</code></pre>
<pre><code>##              V1         V3           V4         V5          V6          V7
## V1  1.000000000 0.30203392 -0.006528852 0.15615240  0.12760571  0.22186692
## V3  0.302033923 1.00000000  0.143364804 0.47658695  0.02576751  0.44025437
## V4 -0.006528852 0.14336480  1.000000000 0.00115185 -0.19030761 -0.05402953
## V5  0.156152397 0.47658695  0.001151850 1.00000000  0.03832312  0.59707508
## V6  0.127605707 0.02576751 -0.190307607 0.03832312  1.00000000 -0.01022692
## V7  0.221866916 0.44025437 -0.054029528 0.59707508 -0.01022692  1.00000000</code></pre>
<p><strong>Trực quan hóa dữ liệu (<code>data visualization</code>)</strong></p>
<p>Do số lượng thuộc tính nhiều nên tôi chỉ trực quan 12 thuộc tính đầu tiên từ tập dữ liệu.</p>
<p><code>Histogram</code> cho 12 thuộc tính đầu tiên:</p>
<pre class="r"><code>par(mfrow=c(3,4))
for(i in 1:12) { 
  hist(dataset[,i], main=names(dataset)[i], breaks = 30)
}</code></pre>
<p><img src="/post/ensemble-learning/index_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p><code>Boxplot</code> cho 12 thuộc tính đầu tiên</p>
<pre class="r"><code>par(mfrow=c(3,4))
for(i in 1:12) {
  boxplot(dataset[,i], main=names(dataset)[i])
}</code></pre>
<p><img src="/post/ensemble-learning/index_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p><strong>Tiền xử lý dữ liệu</strong></p>
<p>Xác định và Loại bỏ các thuộc tính tương quan với nhau cao (&gt;0.75)</p>
<pre class="r"><code># find attributes that are highly corrected
cutoff &lt;- 0.70
correlations &lt;- cor(dataset[,1:13])
highlyCorrelated &lt;- findCorrelation(correlations, cutoff=cutoff)
highlyCorrelated</code></pre>
<pre><code>## integer(0)</code></pre>
<p>Nếu có thì ta có thể xóa như sau:</p>
<pre class="r"><code># create a new dataset without highly corrected features
datasetFeatures &lt;- dataset[,-highlyCorrelated]
dim(datasetFeatures)</code></pre>
<p>Chuẩn hóa dữ liệu (<code>standardizing data</code>):</p>
<pre class="r"><code>preProcValues &lt;- preProcess(dataset, method = c(&quot;center&quot;,&quot;scale&quot;))
data_processed &lt;- predict(preProcValues, dataset)</code></pre>
<p>Kiểm tra dữ liệu sau khi đã chuẩn hóa:</p>
<pre class="r"><code>head(data_processed[,1:7])</code></pre>
<pre><code>##          V1         V3         V4         V5         V6         V7         V8
## 1 0.3479366  0.7113569 -0.2339233  0.4835174 -0.2014474  0.5762362 -0.9533182
## 2 0.3479366  0.7206193 -0.5270583  0.6334035 -1.0361079 -1.3371969 -2.0265590
## 3 0.3479366  0.7206193 -0.1767461  0.7673815 -0.2409648  0.9132274 -0.4608361
## 4 0.3479366  0.7206193 -1.1235677  0.7673815  1.9186015  0.3289631 -2.1495163
## 5 0.3479366  0.7206193 -0.1549082  0.6546592 -0.1097610  0.7529932 -0.6757762
## 6 0.3479366 -1.2416349 -0.1139282 -1.3471047 -0.5107939 -1.1320832 -0.4562658</code></pre>
<p><strong>1. Thuật toán Boosting</strong></p>
<p>Chúng ta sẽ xem xét hai trong số các thuật toán phổ biến nhất của boosting là:</p>
<ul>
<li>C5.0</li>
<li>Stochastic Gradient Boosting</li>
</ul>
<p><strong>Dưới đây là ví dụ huấn luyện hai mô hình này trên R:</strong></p>
<pre class="r"><code># Example of Boosting Algorithms
control &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3)
metric &lt;- &quot;Accuracy&quot;

# C5.0
fit.c50 &lt;- train(Class~., data=dataset, method=&quot;C5.0&quot;, metric=metric, trControl=control)

# Stochastic Gradient Boosting
fit.gbm &lt;- train(Class~., data=dataset, method=&quot;gbm&quot;, metric=metric, trControl=control, verbose=FALSE)</code></pre>
<p>So sánh kết quả hai thuật toán:</p>
<pre class="r"><code># summarize results
boosting_results &lt;- resamples(list(c5.0=fit.c50, gbm=fit.gbm))
summary(boosting_results)</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = boosting_results)
## 
## Models: c5.0, gbm 
## Number of resamples: 30 
## 
## Accuracy 
##           Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
## c5.0 0.8571429 0.9142857 0.9428571 0.9345378 0.9444444    1    0
## gbm  0.8888889 0.9142857 0.9411765 0.9362387 0.9444444    1    0
## 
## Kappa 
##           Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
## c5.0 0.6715328 0.8142060 0.8736462 0.8545695 0.8791046    1    0
## gbm  0.7419355 0.8134991 0.8661417 0.8573574 0.8771949    1    0</code></pre>
<pre class="r"><code>dotplot(boosting_results)</code></pre>
<p><img src="/post/ensemble-learning/index_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Chúng ta có thể thấy thuật toán C5.0 cho kết quả chính xác hơn với độ chính xác là <code>94.28%</code></p>
<p><strong>2. Thuật toán Bagging</strong></p>
<p>Chúng ta sẽ xem xét hai trong số các thuật toán phổ biến nhất của bagging là:</p>
<ul>
<li>Bagged CART</li>
<li>Random Forest</li>
</ul>
<p><strong>Dưới đây là ví dụ huấn luyện hai mô hình này:</strong></p>
<pre class="r"><code># Example of Bagging algorithms
control &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3)
seed &lt;- 7
metric &lt;- &quot;Accuracy&quot;

# Bagged CART
set.seed(seed)
fit.treebag &lt;- train(Class~., data=dataset, method=&quot;treebag&quot;, metric=metric, trControl=control)

# Random Forest
set.seed(seed)
fit.rf &lt;- train(Class~., data=dataset, method=&quot;rf&quot;, metric=metric, trControl=control)</code></pre>
<pre class="r"><code># summarize results
bagging_results &lt;- resamples(list(treebag=fit.treebag, rf=fit.rf))
summary(bagging_results)</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = bagging_results)
## 
## Models: treebag, rf 
## Number of resamples: 30 
## 
## Accuracy 
##              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## treebag 0.8000000 0.8857143 0.9166667 0.9211407 0.9640523 0.9722222    0
## rf      0.8333333 0.8946078 0.9420168 0.9280781 0.9712185 1.0000000    0
## 
## Kappa 
##              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## treebag 0.5648313 0.7552448 0.8208228 0.8265147 0.9216460 0.9407895    0
## rf      0.6504854 0.7801430 0.8722003 0.8412055 0.9350695 1.0000000    0</code></pre>
<pre class="r"><code>dotplot(bagging_results)</code></pre>
<p><img src="/post/ensemble-learning/index_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><strong>3. Thuật toán Stacking</strong></p>
<p>Các bạn có thể kết hợp những mô hình khác nhau trên R sử dụng <strong>caretEnsemble</strong> package.</p>
<p>Với danh sách các caret models, hàm <code>caretStack()</code> có thể sự dụng để chỉ định mô hình bậc cao hơn, từ đó sẽ học cách tìm sự kết hợp tốt nhất những sub-models với nhau.</p>
<p>Ở ví dụ này, chúng ta sẽ sử dụng 5 sub-models cho tập dữ liệu ionosphere:</p>
<ul>
<li><p>Linear Discriminate Analysis (LDA)</p></li>
<li><p>Classification and Regression Trees (CART)</p></li>
<li><p>Logistic Regression (via Generalized Linear Model or GLM)</p></li>
<li><p>k-Nearest Neighbors (kNN)</p></li>
<li><p>Support Vector Machine with a Radial Basis Kernel Function (SVM)</p></li>
</ul>
<p><strong>Huấn luyện 5 model này trên tập dữ liệu:</strong></p>
<pre class="r"><code># Example of Stacking algorithms
# create submodels
control &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
algorithmList &lt;- c(&#39;lda&#39;, &#39;rpart&#39;, &#39;glm&#39;, &#39;knn&#39;, &#39;svmRadial&#39;)
set.seed(seed)
models &lt;- caretList(Class~., data=dataset, trControl=control, methodList=algorithmList)</code></pre>
<pre class="r"><code>results &lt;- resamples(models)
summary(results)</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = results)
## 
## Models: lda, rpart, glm, knn, svmRadial 
## Number of resamples: 30 
## 
## Accuracy 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## lda       0.7352941 0.8285714 0.8591270 0.8580657 0.8880952 0.9428571    0
## rpart     0.7714286 0.8529412 0.8857143 0.8838671 0.9350490 1.0000000    0
## glm       0.7352941 0.8333333 0.8857143 0.8753750 0.9142857 0.9714286    0
## knn       0.7352941 0.8055556 0.8571429 0.8418659 0.8611111 0.9722222    0
## svmRadial 0.8529412 0.9411765 0.9444444 0.9484407 0.9714286 1.0000000    0
## 
## Kappa 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## lda       0.3598326 0.6011806 0.6715328 0.6666689 0.7419355 0.8679245    0
## rpart     0.4838710 0.6479222 0.7490787 0.7436022 0.8551984 1.0000000    0
## glm       0.3855422 0.6279400 0.7508651 0.7206173 0.8134991 0.9378330    0
## knn       0.3368421 0.5258215 0.6653724 0.6214965 0.6830986 0.9387755    0
## svmRadial 0.6586345 0.8665874 0.8788237 0.8870910 0.9385399 1.0000000    0</code></pre>
<pre class="r"><code>dotplot(results)</code></pre>
<p><img src="/post/ensemble-learning/index_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p><strong>Lưu ý:</strong> Khi chúng ta muốn kết hợp các mô hình với nhau sử dụng phương pháp stacking, nên kiểm chứng rằng kết quả dự báo từ các mô hình này tương quan với nhau thấp. Nếu kết quả dự báo của các sub-models tương quan cao với nhau (&gt; 0.75) thì có nghĩa là chúng sẽ cho kết quả dự bạo tương tự như nhau, điều này sẽ làm giảm hiệu quả khi ta kết hợp các mô hình này với nhau.</p>
<pre class="r"><code># correlation between results
modelCor(results)</code></pre>
<pre><code>##                 lda     rpart       glm       knn svmRadial
## lda       1.0000000 0.4001494 0.6029387 0.5112169 0.6008459
## rpart     0.4001494 1.0000000 0.3307816 0.7040301 0.3739250
## glm       0.6029387 0.3307816 1.0000000 0.3472425 0.7387988
## knn       0.5112169 0.7040301 0.3472425 1.0000000 0.4067582
## svmRadial 0.6008459 0.3739250 0.7387988 0.4067582 1.0000000</code></pre>
<pre class="r"><code>splom(results)</code></pre>
<p><img src="/post/ensemble-learning/index_files/figure-html/unnamed-chunk-26-1.png" width="960" /></p>
<p>Nhìn vào kết quả ta có thể thấy các su-models cho kết quả dự báo tương quan với nhau thấp theo từng cặp. Cặp tương quan với nhau nhất là Logistic Regression (GML) và kNN - 0.517, cũng vẫn nhỏ hơn mức quy địn là cao (&gt;0.75)</p>
<p><strong>Nào chúng ta hãy thử kết hợp sử dụng gml:</strong></p>
<pre class="r"><code># stack using glm
stackControl &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
set.seed(seed)
stack.glm &lt;- caretStack(models, method=&quot;glm&quot;, metric=&quot;Accuracy&quot;, trControl=stackControl)
print(stack.glm)</code></pre>
<pre><code>## A glm ensemble of 5 base models: lda, rpart, glm, knn, svmRadial
## 
## Ensemble results:
## Generalized Linear Model 
## 
## 1053 samples
##    5 predictor
##    2 classes: &#39;bad&#39;, &#39;good&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 947, 947, 948, 948, 947, 948, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.9509604  0.8935122</code></pre>
<p>Độ chính xác cải thiện lên 95.25 %. Tuy nhiên so với sử dụng chỉ SVM model thì cũng chưa chênh lệnh nhiều.</p>
<p><strong>Thử sử dụng thuật toán random forest để kết hợp:</strong></p>
<pre class="r"><code># stack using random forest
set.seed(seed)
stack.rf &lt;- caretStack(models, method=&quot;rf&quot;, metric=&quot;Accuracy&quot;, trControl=stackControl)
print(stack.rf)</code></pre>
<pre><code>## A rf ensemble of 5 base models: lda, rpart, glm, knn, svmRadial
## 
## Ensemble results:
## Random Forest 
## 
## 1053 samples
##    5 predictor
##    2 classes: &#39;bad&#39;, &#39;good&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 947, 947, 948, 948, 947, 948, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   2     0.9667798  0.9277270
##   3     0.9655129  0.9250793
##   5     0.9645546  0.9233199
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<p>Độ chính xác cũng cải thiện hơn so với chỉ dùng svm model.</p>

    </div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/data-science/">Data Science</a>
  
  <a class="badge badge-light" href="/tag/data-visualization/">Data Visualization</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/crypto/&amp;text=Ph%c6%b0%c6%a1ng%20ph%c3%a1p%20Ensemble%20Learning%20trong%20Machine%20Learning:%20Boosting,%20Bagging%20v%c3%a0%20Stacking%20%28S%e1%bb%ad%20d%e1%bb%a5ng%20R%20code%29" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/crypto/&amp;t=Ph%c6%b0%c6%a1ng%20ph%c3%a1p%20Ensemble%20Learning%20trong%20Machine%20Learning:%20Boosting,%20Bagging%20v%c3%a0%20Stacking%20%28S%e1%bb%ad%20d%e1%bb%a5ng%20R%20code%29" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Ph%c6%b0%c6%a1ng%20ph%c3%a1p%20Ensemble%20Learning%20trong%20Machine%20Learning:%20Boosting,%20Bagging%20v%c3%a0%20Stacking%20%28S%e1%bb%ad%20d%e1%bb%a5ng%20R%20code%29&amp;body=/post/crypto/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/crypto/&amp;title=Ph%c6%b0%c6%a1ng%20ph%c3%a1p%20Ensemble%20Learning%20trong%20Machine%20Learning:%20Boosting,%20Bagging%20v%c3%a0%20Stacking%20%28S%e1%bb%ad%20d%e1%bb%a5ng%20R%20code%29" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Ph%c6%b0%c6%a1ng%20ph%c3%a1p%20Ensemble%20Learning%20trong%20Machine%20Learning:%20Boosting,%20Bagging%20v%c3%a0%20Stacking%20%28S%e1%bb%ad%20d%e1%bb%a5ng%20R%20code%29%20/post/crypto/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/crypto/&amp;title=Ph%c6%b0%c6%a1ng%20ph%c3%a1p%20Ensemble%20Learning%20trong%20Machine%20Learning:%20Boosting,%20Bagging%20v%c3%a0%20Stacking%20%28S%e1%bb%ad%20d%e1%bb%a5ng%20R%20code%29" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  





  
    
    
    
      
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/cuong-sai/avatar_hu52a603635ecebd45650b162dadabb4e5_12861_270x270_fill_q90_lanczos_center.jpg" alt="Cuong Sai">
      

      <div class="media-body">
        <h5 class="card-title"><a href="/">Cuong Sai</a></h5>
        <h6 class="card-subtitle">PhD student</h6>
        <p class="card-text">My research interests include Industrial AI (Intelligent predictive maintenance), Machine and Deep learning, Time series forecasting, Intelligent machinery fault diagnosis, Prognostics and health management, Error metrics / forecast evaluation.</p>
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://web.facebook.com/CSdatascience" target="_blank" rel="noopener">
        <i class="fab fa-facebook"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.uk/citations?hl=en&amp;user=qhiD3RUAAAAJ" target="_blank" rel="noopener">
        <i class="fab fa-google-sholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/svcuong" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  







<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "cuongsai" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>








  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/post/crypto/">Cách scrape một trang web bằng R. Scrape và so sánh dữ liệu lịch sử thị trường  tiền điện tử từ CoinMarketCap</a></li>
      
      <li><a href="/post/s-d-ng-k-t-h-p-r-va-python-trong-data-science/">Sử dụng kết hợp R và Python trong data science</a></li>
      
      <li><a href="/post/remove-outliers/">Sử dụng thống kê để xác định và loại bỏ dữ liệu ngoại lai cho machine learning trong R và Python</a></li>
      
      <li><a href="/project/pdm-project/">The PdM Project</a></li>
      
      <li><a href="/project/forvision-project/">The Forvision Project</a></li>
      
    </ul>
  </div>
  




 
  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js" integrity="sha512-7t8APmYpzEsZP7CYoA7RfMPV9Bb+PJHa9x2WiUnDXZx3XHveuyWUtvNOexhkierl5flZ3tr92dP1mMS+SGlD+A==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    <script id="dsq-count-scr" src="https://cuongsai.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3b2b658c61ebd725bd5fc606c89fe44c.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    
    Published with
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic Website Builder</a>
    

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
