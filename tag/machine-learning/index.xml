<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning | Khoa Học Dữ Liệu</title>
    <link>/tag/machine-learning/</link>
      <atom:link href="/tag/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>vi-en</language><copyright>© 2020 Cuong Sai. All Rights Reserved</copyright><lastBuildDate>Tue, 01 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu47efca792e1e7000f9078d7b8f1dac48_31011_512x512_fill_lanczos_center_2.PNG</url>
      <title>Machine Learning</title>
      <link>/tag/machine-learning/</link>
    </image>
    
    <item>
      <title>Cách dùng keras và tensorflow trong R. So sánh R interface và Python interface cho keras.</title>
      <link>/post/r-python-machine-learning/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/post/r-python-machine-learning/</guid>
      <description>


&lt;hr /&gt;
&lt;p&gt;Nội dung của bài bao gồm:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;#sec1&#34;&gt;1. Cài đặt môi trường làm việc để kết hợp R và Python&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;#sec2&#34;&gt;2. So sánh R interface và Python interface cho keras với bài toán MNIST nổi tiếng&lt;/a&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;sec1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1 Cài đặt&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1.1 Cài đặt keras và tensorflow trong R&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Để cài đặt Keras và Tensorflow trong R các bạn dùng các lệnh sau:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;keras&amp;quot;)
install.packages(“tensorflow”)
library(keras)
install_keras()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;1.2 Cài đặt keras và tensorflow trong Python (sử dụng anaconda)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Để làm việc về khoa học dữ liệu với ngôn ngữ &lt;code&gt;Python&lt;/code&gt;, một cách đơn giản nhất là tải về và cài đặt &lt;code&gt;Anaconda&lt;/code&gt; - nền tảng (&lt;code&gt;platform&lt;/code&gt;) mã nguồn mở về khoa học dữ liệu thông dụng nhất hiện nay hỗ trợ làm việc với &lt;code&gt;Python&lt;/code&gt; và &lt;code&gt;R&lt;/code&gt;. Nếu chưa biết cách sử dụng &lt;code&gt;R&lt;/code&gt; trong &lt;code&gt;Anaconda&lt;/code&gt; thì các bạn có thể đọc bài hướng dẫn trước tại &lt;a href=&#34;https://svcuong.github.io/post/r-jupyter/r-jupyter/&#34;&gt;đây&lt;/a&gt;. Download và cài đặt &lt;code&gt;Anaconda&lt;/code&gt; tại &lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;đây&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Lưu ý:&lt;/code&gt; trong khi cài các đặt bạn nhớ là tích vào mục &lt;code&gt;Add Anaconda to my PATH environment variable&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/conda0.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Sau khi đã cài xong &lt;code&gt;Anaconda&lt;/code&gt;, các bạn vào &lt;code&gt;Anaconda Prompt&lt;/code&gt; để tạo một môi trường mới chứa các thư viện cần thiết như sau:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conda create -n r-env python=3.7 scikit-learn pandas numpy matplotlib keras tensorflow&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/conda1.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Câu lệnh trên có nghĩa là:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Khởi tạo môi trường anaconda mới với tên &lt;code&gt;r-env&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Cài &lt;code&gt;python&lt;/code&gt; phiên bản 3.7 với các thư viện scikit-learn, pandas, numpy, matplotlib, keras và tensorflow cho môi trường này&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kiểm tra xem môi trường &lt;code&gt;r-env&lt;/code&gt; đã được tạo trong &lt;code&gt;Anaconda&lt;/code&gt; chưa bằng lệnh &lt;code&gt;conda env list&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/conda2.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.3 Thiết lập môi trường làm việc để sử dụng kết hợp R và Python trong R&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Để sử dụng &lt;code&gt;Python&lt;/code&gt; trong &lt;code&gt;R&lt;/code&gt; chúng ta sử dụng gói &lt;code&gt;reticulate&lt;/code&gt;. Để biết cách kết hợp &lt;code&gt;R&lt;/code&gt; và &lt;code&gt;Python&lt;/code&gt; trong &lt;code&gt;R&lt;/code&gt; các bạn có thể đọc bài trước tại &lt;a href=&#34;https://svcuong.github.io/post/s-d-ng-k-t-h-p-r-va-python-trong-data-science/&#34;&gt;đây&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Nạp thư viện &lt;code&gt;reticulate&lt;/code&gt; và sử dụng hàm &lt;code&gt;conda_list()&lt;/code&gt; để kiểm tra danh sách môi trường &lt;code&gt;Anaconda&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
conda_list()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    name                                               python
## 1 r-env C:\\Users\\svcuo\\Anaconda3\\envs\\r-env\\python.exe&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vậy là đã có môi trường &lt;code&gt;r-env&lt;/code&gt; mới khởi tạo. Để chọn môi trường này sử dụng trong &lt;code&gt;R&lt;/code&gt; chúng ta sử dụng hàm &lt;code&gt;use_condaenv()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;use_condaenv(&amp;quot;r-env&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;sec2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2. So sánh R interface và Python interface cho keras với bài toán MNIST nổi tiếng&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Chú ý&lt;/code&gt;: do sử dụng kết hợp &lt;code&gt;R&lt;/code&gt; và &lt;code&gt;Python&lt;/code&gt; trong cùng một &lt;code&gt;R Notebook&lt;/code&gt; nên tôi sẽ chú thích &lt;code&gt;R&lt;/code&gt; với mỗi &lt;code&gt;R code chunk&lt;/code&gt; và &lt;code&gt;Python&lt;/code&gt; với mỗi &lt;code&gt;Python code chunk&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;sử-dụng-r-interface-cho-keras&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2.1 Sử dụng R interface cho keras&lt;/h4&gt;
&lt;p&gt;Nạp tập dữ liệu &lt;code&gt;MNIST&lt;/code&gt; từ &lt;code&gt;keras&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R code
library(keras)
mnist &amp;lt;- dataset_mnist()
train_images &amp;lt;- mnist$train$x
train_labels &amp;lt;- mnist$train$y
test_images &amp;lt;- mnist$test$x
test_labels &amp;lt;- mnist$test$y&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra dữ liệu:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R code
dim(train_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 60000    28    28&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(train_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 60000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(test_images)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10000    28    28&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(test_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thử hiển thị 5th digit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R code
digit &amp;lt;- train_images[5,,]
plot(as.raster(digit, max = 255))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/r-python-machine-learning/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
&lt;strong&gt;Hướng dẫn thao tác với tensors trong R:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R code
slice1 &amp;lt;- train_images[10:99,,]
dim(slice1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 90 28 28&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R code
slice2 &amp;lt;- train_images[10:99,1:28,1:28]
dim(slice2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 90 28 28&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;slice3 &amp;lt;- train_images[, 15:28, 15:28]
dim(slice3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 60000    14    14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Thiết kế cấu trúc network model:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R code
model &amp;lt;- keras_model_sequential() %&amp;gt;%
  layer_dense(units = 512, activation = &amp;quot;relu&amp;quot;, input_shape = c(28 * 28)) %&amp;gt;%
  layer_dense(units = 10, activation = &amp;quot;softmax&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Model Summary :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R code
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Model: &amp;quot;sequential&amp;quot;
## ________________________________________________________________________________
## Layer (type)                        Output Shape                    Param #     
## ================================================================================
## dense (Dense)                       (None, 512)                     401920      
## ________________________________________________________________________________
## dense_1 (Dense)                     (None, 10)                      5130        
## ================================================================================
## Total params: 407,050
## Trainable params: 407,050
## Non-trainable params: 0
## ________________________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bước tiếp theo, compile model với &lt;code&gt;loss function, optimizer và metrics&lt;/code&gt; tương ứng:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;% compile(
  optimizer = &amp;quot;rmsprop&amp;quot;,
  loss = &amp;quot;categorical_crossentropy&amp;quot;,
  metrics = c(&amp;quot;accuracy&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chuẩn bị dữ liệu để huấn luyện mô hình:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_images &amp;lt;- array_reshape(train_images, c(60000, 28 * 28))
train_images &amp;lt;- train_images / 255
test_images &amp;lt;- array_reshape(test_images, c(10000, 28 * 28))
test_images &amp;lt;- test_images / 255&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_labels &amp;lt;- to_categorical(train_labels)
test_labels &amp;lt;- to_categorical(test_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Huấn luyện mô hình:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;% fit(
  train_images, 
  train_labels, 
  epochs = 5, 
  batch_size = 128)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Đánh giá độ chính xác của mô hình:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metrics &amp;lt;- model %&amp;gt;% evaluate(test_images, test_labels)
metrics&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $loss
## [1] 0.06532291
## 
## $accuracy
## [1] 0.9802&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dự đoán với dữ liệu mới:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model %&amp;gt;% predict_classes(test_images[1:10,])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 7 2 1 0 4 1 4 9 5 9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.2 Sử dụng Python interface cho keras trong môi trường R&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Nạp tập dữ liệu &lt;code&gt;MNIST&lt;/code&gt; từ &lt;code&gt;keras&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
from keras.datasets import mnist&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Using TensorFlow backend.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;(train_images, train_labels), (test_images, test_labels) = mnist.load_data()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra dữ liệu:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
train_images.shape&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (60000, 28, 28)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
train_labels.shape&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (60000,)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
test_images.shape&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (10000, 28, 28)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
test_labels.shape&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (10000,)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Thiết kế cấu trúc network model:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Dense(512, activation=&amp;#39;relu&amp;#39;, input_shape=(28 * 28,)))
model.add(layers.Dense(10, activation=&amp;#39;softmax&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile model với &lt;code&gt;loss function, optimizer và metrics&lt;/code&gt; tương ứng:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
model.compile(optimizer=&amp;#39;rmsprop&amp;#39;,
loss=&amp;#39;categorical_crossentropy&amp;#39;,
metrics=[&amp;#39;accuracy&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chuẩn bị dữ liệu để huấn luyện mô hình:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype(&amp;#39;float32&amp;#39;) / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype(&amp;#39;float32&amp;#39;) / 255&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
from keras.utils import to_categorical
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Huấn luyện mô hình:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
model.fit(train_images, train_labels, epochs=5, batch_size=128)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Đánh giá độ chính xác của mô hình:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
test_loss, test_acc = model.evaluate(test_images, test_labels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(&amp;#39;test_acc:&amp;#39;, test_acc)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## test_acc: 0.980400025844574&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dự đoán với dữ liệu mới:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Python
model.predict_classes(test_images[:10,:])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Download và trực quan hóa dữ liệu Covid-19 từ John Hopkins database (sử dụng Python code)</title>
      <link>/post/covid-19-python/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/post/covid-19-python/</guid>
      <description>&lt;p&gt;&lt;code&gt;Covid-19&lt;/code&gt; là một đại dịch bệnh truyền nhiễm với tác nhân là virus &lt;code&gt;SARS-CoV-2&lt;/code&gt;, hiện đang ảnh hưởng và gây thiệt hại nặng nề trên phạm vi toàn cầu. Kể từ khi đại dịch &lt;code&gt;Covid-19&lt;/code&gt; bắt đầu xuất hiện ở Vũ Hán - Trung Quốc đến nay, cái tên trường Đại học Jonhs Hopkins (Mỹ) được nhắc đi nhắc lại hằng ngày trên các phương tiện truyền thông và là một trong những cụm từ được trích dẫn nhiều nhất. Lý do đó là Đại học Johns Hopkins đã phát triển một trong những hệ thống theo dõi dữ liệu COVID-19 bền bỉ và đáng tin cậy nhất trên thế giới cho đến nay.&lt;/p&gt;
&lt;p&gt;Dữ liệu Covid-19 được đại học &lt;code&gt;John Hopkins&lt;/code&gt; thu thập và cập nhật hàng ngày tại đây 
&lt;a href=&#34;https://github.com/CSSEGISandData/COVID-19&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Hopkins database&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Trong bài này để hiểu hơn về đại dịch này tôi sẽ hướng dẫn các bạn cách download dữ liệu Covid-19 từ 
&lt;a href=&#34;https://github.com/CSSEGISandData/COVID-19&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Hopkins database&lt;/a&gt; và thực hành các thao tác chuẩn bị dữ liệu (làm sạch và biến đổi) với thư viện &lt;code&gt;pandas&lt;/code&gt; và trực quan hóa dữ liệu với thư viện &lt;code&gt;maplotlib&lt;/code&gt; sử dụng ngôn ngữ Python. Sau khi đọc xong bài này các bạn sẽ nắm được:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Cách download dữ liệu Covid-19 từ &lt;code&gt;Jonh Hopkins&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cách làm sạch và biến đổi dữ liệu dạng &lt;code&gt;data frame&lt;/code&gt; với thư viện &lt;code&gt;pandas&lt;/code&gt;: xử lý dữ liệu bị thiếu, gộp các dataframes, chuyển đổi dữ liệu từ dạng &lt;code&gt;wide format&lt;/code&gt; sang dạng &lt;code&gt;long fromat&lt;/code&gt;, subset,&amp;hellip;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cách trực quan hóa dữ liệu &lt;code&gt;Covid-19&lt;/code&gt; sử dụng thư viện &lt;code&gt;matplotlib&lt;/code&gt;: Pie chart, Bar chart, Line chart, Multi-Line Chart, xử lý dữ liệu &lt;code&gt;date&lt;/code&gt; trong vẽ biểu đồ,&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Từ đó các bạn có thể phát triển các kỹ thuật trên thành các &lt;code&gt;Data visualization Dashboards&lt;/code&gt; hoặc là web tương tác để &lt;code&gt;tracking&lt;/code&gt; tình hình &lt;code&gt;Covid-19&lt;/code&gt; trên toàn thế giới tương tự như 
&lt;a href=&#34;https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Hopkins University Dashboard&lt;/a&gt;, 
&lt;a href=&#34;https://covid19.who.int/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WHO COVID-19 Dashboard&lt;/a&gt;,&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;nội-dung-chính-của-bài-bao-gồm&#34;&gt;Nội dung chính của bài bao gồm:&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;#prepare-data&#34;&gt;1. Download &amp;amp; chuẩn bị dữ liệu Covid-19 sử dụng thư viện pandas&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;#data-visualization&#34;&gt;2. Trực quan hóa dữ liệu Covid-19 sử dụng thư viện matploblib&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;prepare-data&#34;&gt;1. Download và chuẩn bị dữ liệu&lt;/h2&gt;
&lt;p&gt;Trước hết để thực hành chúng ta cần nạp các thư viện cần thiết trên &lt;code&gt;Python&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, timedelta
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Để thực hành tôi sẽ load 3 tập dữ liệu sau từ kho dữ liệu qua &lt;code&gt;url_links&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Confirmed:&lt;/code&gt; (Số trường hợp mới phát hiện)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Deaths:&lt;/code&gt; (Số trường hợp tử vong)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Recovered:&lt;/code&gt; (Số trường hợp hồi phục)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;url_confd = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&#39;
url_death = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39;
url_recvd = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv&#39;
df_confd = pd.read_csv(url_confd)
df_death = pd.read_csv(url_death)
df_recvd = pd.read_csv(url_recvd)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra thông tin các tập dữ liệu này:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(df_confd.info())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 266 entries, 0 to 265
Columns: 224 entries, Province/State to 8/28/20
dtypes: float64(2), int64(220), object(2)
memory usage: 465.6+ KB
None
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(df_death.info())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 266 entries, 0 to 265
Columns: 224 entries, Province/State to 8/28/20
dtypes: float64(2), int64(220), object(2)
memory usage: 465.6+ KB
None
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(df_recvd.info())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 253 entries, 0 to 252
Columns: 223 entries, Province/State to 8/27/20
dtypes: float64(2), int64(219), object(2)
memory usage: 440.9+ KB
None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra 5 hàng đầu tiên của tập dữ liệu &lt;code&gt;df_confd&lt;/code&gt; (2 tập còn lại tương tự):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(df_confd.head(5))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \
0            NaN    Afghanistan  33.93911  67.709953        0        0   
1            NaN        Albania  41.15330  20.168300        0        0   
2            NaN        Algeria  28.03390   1.659600        0        0   
3            NaN        Andorra  42.50630   1.521800        0        0   
4            NaN         Angola -11.20270  17.873900        0        0   

   1/24/20  1/25/20  1/26/20  1/27/20  ...  8/19/20  8/20/20  8/21/20  \
0        0        0        0        0  ...    37599    37856    37894   
1        0        0        0        0  ...     7812     7967     8119   
2        0        0        0        0  ...    39847    40258    40667   
3        0        0        0        0  ...     1024     1024     1045   
4        0        0        0        0  ...     2015     2044     2068   

   8/22/20  8/23/20  8/24/20  8/25/20  8/26/20  8/27/20  8/28/20  
0    37953    37999    38054    38070    38113    38129    38140  
1     8275     8427     8605     8759     8927     9083     9195  
2    41068    41460    41858    42228    42619    43016    43403  
3     1045     1045     1060     1060     1098     1098     1124  
4     2134     2171     2222     2283     2332     2415     2471  

[5 rows x 224 columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Trích xuất thông tin về ngày từ tập dữ liệu:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dates = df_confd.columns[4:]
print(dates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Index([&#39;1/22/20&#39;, &#39;1/23/20&#39;, &#39;1/24/20&#39;, &#39;1/25/20&#39;, &#39;1/26/20&#39;, &#39;1/27/20&#39;,
       &#39;1/28/20&#39;, &#39;1/29/20&#39;, &#39;1/30/20&#39;, &#39;1/31/20&#39;,
       ...
       &#39;8/19/20&#39;, &#39;8/20/20&#39;, &#39;8/21/20&#39;, &#39;8/22/20&#39;, &#39;8/23/20&#39;, &#39;8/24/20&#39;,
       &#39;8/25/20&#39;, &#39;8/26/20&#39;, &#39;8/27/20&#39;, &#39;8/28/20&#39;],
      dtype=&#39;object&#39;, length=220)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Các tập dữ liệu này được lưu ở dạng &lt;code&gt;wide format&lt;/code&gt; do đó chúng ta cần chuyển chúng dạng &lt;code&gt;long fromat&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dates = df_confd.columns[4:]
long_df_confd = df_confd.melt(id_vars=[&#39;Province/State&#39;, &#39;Country/Region&#39;, &#39;Lat&#39;, &#39;Long&#39;], 
                            value_vars=dates, var_name=&#39;Date&#39;, value_name=&#39;Confirmed&#39;)

long_df_death = df_death.melt(id_vars=[&#39;Province/State&#39;, &#39;Country/Region&#39;, &#39;Lat&#39;, &#39;Long&#39;], 
                            value_vars=dates, var_name=&#39;Date&#39;, value_name=&#39;Deaths&#39;)

long_df_recvd = df_recvd.melt(id_vars=[&#39;Province/State&#39;, &#39;Country/Region&#39;, &#39;Lat&#39;, &#39;Long&#39;], 
                            value_vars=dates, var_name=&#39;Date&#39;, value_name=&#39;Recovered&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra dữ liệu sau khi đã chuyển:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(long_df_confd.head(5))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  Province/State Country/Region       Lat       Long     Date  Confirmed
0            NaN    Afghanistan  33.93911  67.709953  1/22/20          0
1            NaN        Albania  41.15330  20.168300  1/22/20          0
2            NaN        Algeria  28.03390   1.659600  1/22/20          0
3            NaN        Andorra  42.50630   1.521800  1/22/20          0
4            NaN         Angola -11.20270  17.873900  1/22/20          0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(long_df_death.head(5))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  Province/State Country/Region       Lat       Long     Date  Deaths
0            NaN    Afghanistan  33.93911  67.709953  1/22/20       0
1            NaN        Albania  41.15330  20.168300  1/22/20       0
2            NaN        Algeria  28.03390   1.659600  1/22/20       0
3            NaN        Andorra  42.50630   1.521800  1/22/20       0
4            NaN         Angola -11.20270  17.873900  1/22/20       0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(long_df_recvd.head(5))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  Province/State Country/Region       Lat       Long     Date  Recovered
0            NaN    Afghanistan  33.93911  67.709953  1/22/20          0
1            NaN        Albania  41.15330  20.168300  1/22/20          0
2            NaN        Algeria  28.03390   1.659600  1/22/20          0
3            NaN        Andorra  42.50630   1.521800  1/22/20          0
4            NaN         Angola -11.20270  17.873900  1/22/20          0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gộp 3 tập dữ liệu này thành 1 dataframe:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final_df = pd.merge(left=long_df_confd, right=long_df_death, how=&#39;left&#39;,
                      on=[&#39;Province/State&#39;, &#39;Country/Region&#39;, &#39;Date&#39;, &#39;Lat&#39;, &#39;Long&#39;])
final_df = pd.merge(left=final_df, right=long_df_recvd, how=&#39;left&#39;,
                      on=[&#39;Province/State&#39;, &#39;Country/Region&#39;, &#39;Date&#39;, &#39;Lat&#39;, &#39;Long&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chuyển cột dữ liệu ngày về dạng &lt;code&gt;date&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final_df[&#39;Date&#39;] = pd.to_datetime(final_df[&#39;Date&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra bảng dữ liệu thu được:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(final_df.head(5))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  Province/State Country/Region       Lat       Long       Date  Confirmed  \
0            NaN    Afghanistan  33.93911  67.709953 2020-01-22          0   
1            NaN        Albania  41.15330  20.168300 2020-01-22          0   
2            NaN        Algeria  28.03390   1.659600 2020-01-22          0   
3            NaN        Andorra  42.50630   1.521800 2020-01-22          0   
4            NaN         Angola -11.20270  17.873900 2020-01-22          0   

   Deaths  Recovered  
0       0        0.0  
1       0        0.0  
2       0        0.0  
3       0        0.0  
4       0        0.0  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra kích thước của bảng dữ liệu thu được:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(final_df.shape)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(58520, 8)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra khoảng thời gian của dữ liệu được thu thập:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a = final_df.Date.value_counts().sort_index()
print(&#39;Ngày bắt đầu là:&#39;,a.index[0])
print(&#39;Ngày hiện tại là:&#39;,a.index[-1])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Ngày bắt đầu là: 2020-01-22 00:00:00
Ngày hiện tại là: 2020-08-28 00:00:00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra &lt;code&gt;missing values (NaN)&lt;/code&gt; trong tập dữ liệu:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final_df.isna().sum()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Province/State    40515
Country/Region        0
Lat                   0
Long                  0
Date                  0
Confirmed             0
Deaths                0
Recovered          4161
dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Đánh giá phần trăm &lt;code&gt;missing values&lt;/code&gt; của từng cột dữ liệu:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;NAN = [(c, final_df[c].isna().mean()*100) for c in final_df]
NAN = pd.DataFrame(NAN, columns=[&amp;quot;column_name&amp;quot;, &amp;quot;percentage&amp;quot;])
print(NAN)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;      column_name  percentage
0  Province/State   69.548872
1  Country/Region    0.000000
2             Lat    0.000000
3            Long    0.000000
4            Date    0.000000
5       Confirmed    0.000000
6          Deaths    0.000000
7       Recovered    7.142857
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ta thấy cột &lt;code&gt;Province/State&lt;/code&gt; có gần &lt;code&gt;69.55%&lt;/code&gt; dữ liệu bị thiếu và cột &lt;code&gt;Recovered&lt;/code&gt; có &lt;code&gt;7,14%&lt;/code&gt;. Vì vậy chúng ta cần xử lý các giá trị thiếu này:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Thay thế nan thành 0 cho cột Recovered
final_df[&#39;Recovered&#39;] = final_df[&#39;Recovered&#39;].fillna(0)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Thay thế nan thành Unknown cho cột Province/State
final_df[&amp;quot;Province/State&amp;quot;]= final_df[&amp;quot;Province/State&amp;quot;].fillna(&#39;Unknown&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra xem trong dữ liệu còn &lt;code&gt;missing values&lt;/code&gt; không:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final_df.isna().sum()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Province/State    0
Country/Region    0
Lat               0
Long              0
Date              0
Confirmed         0
Deaths            0
Recovered         0
dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra kiểu dữ liệu:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(final_df.dtypes)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Province/State            object
Country/Region            object
Lat                      float64
Long                     float64
Date              datetime64[ns]
Confirmed                  int64
Deaths                     int64
Recovered                float64
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thay đổi kiểu dữ liệu cho các cột &lt;code&gt;Confirmed, Deaths và Recovered&lt;/code&gt; thành &lt;code&gt;int&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final_df[[&amp;quot;Confirmed&amp;quot;,&amp;quot;Deaths&amp;quot;,&amp;quot;Recovered&amp;quot;]] = final_df[[&amp;quot;Confirmed&amp;quot;,&amp;quot;Deaths&amp;quot;,&amp;quot;Recovered&amp;quot;]].astype(int)
print(final_df.dtypes)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Province/State            object
Country/Region            object
Lat                      float64
Long                     float64
Date              datetime64[ns]
Confirmed                  int32
Deaths                     int32
Recovered                  int32
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tạo thuộc tính mới &lt;code&gt;Active&lt;/code&gt; (Số trường hợp còn đang nhiễm sau khi đã trừ đi số trường hợp tử vong và hồi phục): 
$$Active = Confirmed - Deaths - Recovered$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final_df[&#39;Active&#39;] = final_df[&#39;Confirmed&#39;] - final_df[&#39;Deaths&#39;] - final_df[&#39;Recovered&#39;]
print(final_df.head(5))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  Province/State Country/Region       Lat       Long       Date  Confirmed  \
0        Unknown    Afghanistan  33.93911  67.709953 2020-01-22          0   
1        Unknown        Albania  41.15330  20.168300 2020-01-22          0   
2        Unknown        Algeria  28.03390   1.659600 2020-01-22          0   
3        Unknown        Andorra  42.50630   1.521800 2020-01-22          0   
4        Unknown         Angola -11.20270  17.873900 2020-01-22          0   

   Deaths  Recovered  Active  
0       0          0       0  
1       0          0       0  
2       0          0       0  
3       0          0       0  
4       0          0       0  
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;data-visualization&#34;&gt;2. Trực quan hóa dữ liệu&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;2.1 Tổng quan tình hình Covid -19 trên toàn thế giới tính tới thời điểm đang viết bài này:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kiểm tra tổng số nước trên toàn thế giới trong tập dữ liệu:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;len(final_df[&#39;Country/Region&#39;].unique())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;188
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tổng các cases trên toàn thế giới:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame(pd.to_numeric(final_df[[&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;]].sum()),dtype=np.float64).transpose()
df[&#39;Last date&#39;] = max(final_df[&#39;Date&#39;])
print(df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;      Confirmed      Deaths    Recovered       Active  Last date
0  1.492646e+09  67290986.0  798778726.0  626576735.0 2020-08-28
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tạo &lt;code&gt;Pie chart&lt;/code&gt; so sánh các cases trên toàn thế giới:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cases = [&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;]
colors = [&#39;gold&#39;, &#39;yellowgreen&#39;, &#39;lightcoral&#39;, &#39;lightskyblue&#39;]
explode = (0.1, 0, 0, 0)  # explode 1st slice
sizes = sum(df.loc[:, &#39;Confirmed&#39;:&#39;Active&#39;].values)
explode = (0.1, 0, 0, 0)  # explode 1st slice

# Plot
f = plt.figure(figsize=(8,8))
plt.pie(sizes, explode=explode, 
        textprops=dict(size=15,color=&#39;black&#39;),
        labels=cases, 
        colors=colors,
        autopct=&#39;%1.1f%%&#39;, 
        shadow=True, 
        startangle=140)
plt.axis(&#39;equal&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_54_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.2 Top 10 nước có số trường hợp (confirmed, deaths, recovered and active cases) lớn nhất&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tính tổng các &lt;code&gt;cases&lt;/code&gt; của từng nước tính đến thười điểm hiện tại:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_countries = final_df.copy().drop([&#39;Lat&#39;,&#39;Long&#39;,&#39;Province/State&#39;, &#39;Date&#39;],axis =1)
df_countries = df_countries.groupby([&amp;quot;Country/Region&amp;quot;]).sum()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Top 10 nước có &lt;code&gt;confirmed cases&lt;/code&gt; lớn nhất:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f = plt.figure(figsize=(10,5))
f.add_subplot(111)
plt.axes(axisbelow=True)
plt.barh(df_countries.sort_values(&#39;Confirmed&#39;)[&amp;quot;Confirmed&amp;quot;].index[-10:],df_countries.sort_values(&#39;Confirmed&#39;)[&amp;quot;Confirmed&amp;quot;].values[-10:],color=&amp;quot;darkcyan&amp;quot;)
plt.tick_params(size=5,labelsize = 13)
plt.xlabel(&amp;quot;Confirmed Cases&amp;quot;,fontsize=18)
plt.title(&amp;quot;Top 10 Countries (Confirmed Cases)&amp;quot;,fontsize=20)
plt.grid(alpha=0.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_59_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Top 10 nước có &lt;code&gt;Deaths&lt;/code&gt; lớn nhất:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f = plt.figure(figsize=(10,5))
f.add_subplot(111)

plt.axes(axisbelow=True)
plt.barh(df_countries.sort_values(&#39;Deaths&#39;)[&amp;quot;Deaths&amp;quot;].index[-10:],df_countries.sort_values(&#39;Deaths&#39;)[&amp;quot;Deaths&amp;quot;].values[-10:],color=&amp;quot;crimson&amp;quot;)
plt.tick_params(size=5,labelsize = 13)
plt.xlabel(&amp;quot;Deaths Cases&amp;quot;,fontsize=18)
plt.title(&amp;quot;Top 10 Countries (Deaths)&amp;quot;,fontsize=20)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_61_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Top 10 nước có &lt;code&gt;Recovered Cases&lt;/code&gt; lớn nhất:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f = plt.figure(figsize=(10,5))
f.add_subplot(111)

plt.axes(axisbelow=True)
plt.barh(df_countries.sort_values(&#39;Recovered&#39;)[&amp;quot;Recovered&amp;quot;].index[-10:],df_countries.sort_values(&#39;Recovered&#39;)[&amp;quot;Recovered&amp;quot;].values[-10:],color=&amp;quot;limegreen&amp;quot;)
plt.tick_params(size=5,labelsize = 13)
plt.xlabel(&amp;quot;Recovered Cases&amp;quot;,fontsize=18)
plt.title(&amp;quot;Top 10 Countries (Recovered Cases)&amp;quot;,fontsize=20)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_63_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Top 10 nước có &lt;code&gt;Active Cases&lt;/code&gt; lớn nhất:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f = plt.figure(figsize=(10,5))
f.add_subplot(111)

plt.axes(axisbelow=True)
plt.barh(df_countries.sort_values(&#39;Active&#39;)[&amp;quot;Active&amp;quot;].index[-10:],df_countries.sort_values(&#39;Active&#39;)[&amp;quot;Active&amp;quot;].values[-10:],color=&amp;quot;darkorange&amp;quot;)
plt.tick_params(size=5,labelsize = 13)
plt.xlabel(&amp;quot;Active Cases&amp;quot;,fontsize=18)
plt.title(&amp;quot;Top 10 Countries (Active Cases)&amp;quot;,fontsize=20)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_65_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.3 Mức độ phát triển của Covid-19 theo thời gian trên toàn thế giới&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tính tổng các &lt;code&gt;cases&lt;/code&gt; trên toàn thế giới theo thời gian&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_world = final_df.groupby([&amp;quot;Date&amp;quot;])[[&amp;quot;Confirmed&amp;quot;,&amp;quot;Active&amp;quot;,&amp;quot;Recovered&amp;quot;,&amp;quot;Deaths&amp;quot;]].sum().reset_index()
df_world.set_index(&#39;Date&#39;,inplace=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mức độ phát triển của &lt;code&gt;Confirmed cases&lt;/code&gt; trên toàn thế giới theo thời gian:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create figure and plot space
fig, ax = plt.subplots(figsize=(10, 6))

# Add x-axis and y-axis
ax.bar(df_world.index.values,
        df_world[&#39;Confirmed&#39;],
        color=&#39;blue&#39;)

# Set title and labels for axes
ax.set(xlabel=&amp;quot;Date&amp;quot;,
       ylabel=&amp;quot;Confirmed cases&amp;quot;,
       title=&amp;quot;Confirmed Cases In Each Day&amp;quot;)

# Rotate tick marks on x-axis
plt.setp(ax.get_xticklabels(), rotation=45)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_70_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Mức độ phát triển của &lt;code&gt;Deaths&lt;/code&gt; trên toàn thế giới theo thời gian:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create figure and plot space
fig, ax = plt.subplots(figsize=(10, 6))

# Add x-axis and y-axis
ax.bar(df_world.index.values,
        df_world[&#39;Deaths&#39;],
        color=&#39;red&#39;)

# Set title and labels for axes
ax.set(xlabel=&amp;quot;Date&amp;quot;,
       ylabel=&amp;quot;Deaths&amp;quot;,
       title=&amp;quot;Deaths In Each Day&amp;quot;)

# Rotate tick marks on x-axis
plt.setp(ax.get_xticklabels(), rotation=45)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_72_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Mức độ phát triển của &lt;code&gt;Recovered cases&lt;/code&gt; trên toàn thế giới theo thời gian:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create figure and plot space
fig, ax = plt.subplots(figsize=(10, 6))

# Add x-axis and y-axis
ax.bar(df_world.index.values,
        df_world[&#39;Recovered&#39;],
        color=&#39;purple&#39;)

# Set title and labels for axes
ax.set(xlabel=&amp;quot;Date&amp;quot;,
       ylabel=&amp;quot;Recovered cases&amp;quot;,
       title=&amp;quot;Recovered Cases In Each Day&amp;quot;)

# Rotate tick marks on x-axis
plt.setp(ax.get_xticklabels(), rotation=45)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_74_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Mức độ phát triển của &lt;code&gt;Active Cases&lt;/code&gt; trên toàn thế giới theo thời gian:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create figure and plot space
fig, ax = plt.subplots(figsize=(10, 6))

# Add x-axis and y-axis
ax.bar(df_world.index.values,
        df_world[&#39;Active&#39;],
        color= &#39;green&#39;)

# Set title and labels for axes
ax.set(xlabel=&amp;quot;Date&amp;quot;,
       ylabel=&amp;quot;Active Cases&amp;quot;,
       title=&amp;quot;Active Cases In Each Day&amp;quot;)

# Rotate tick marks on x-axis
plt.setp(ax.get_xticklabels(), rotation=45)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_76_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.4 Hiển thị tất cả các cases trên thế giới theo thời gian&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create figure and plot space
fig, ax = plt.subplots(figsize=(12, 6))

# Add x-axis and y-axis
ax.plot(df_world.index.values,
        df_world[&#39;Confirmed&#39;],
        color=&#39;blue&#39;, label = &#39;Confirmed Cases&#39;)

ax.plot(df_world.index.values,
        df_world[&#39;Deaths&#39;],
        color=&#39;red&#39;, label = &#39;Deaths&#39;)

ax.plot(df_world.index.values,
        df_world[&#39;Recovered&#39;],
        color=&#39;purple&#39;, label = &#39;Recovered Cases&#39;)


ax.plot(df_world.index.values,
        df_world[&#39;Active&#39;],
        color= &#39;green&#39;,  label= &#39;Active Cases&#39;)


# Set title and labels for axes
ax.set(xlabel=&amp;quot;Date&amp;quot;,
       ylabel=&amp;quot;Cases&amp;quot;,
       title=&amp;quot;COVID-19 Cases In Each Day&amp;quot;)

# Rotate tick marks on x-axis
plt.setp(ax.get_xticklabels(), rotation=45)
plt.legend(loc=&amp;quot;upper left&amp;quot;)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_78_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.5 Tổng số lượng các quốc gia trên thế giới xuất hiện dịch bệnh Covid-19 theo thời gian&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Tính tổng số lượng các nước xuất hiện dịch Covid-19 theo thời gian
case_nums_country = df_confd.groupby(&amp;quot;Country/Region&amp;quot;).sum().drop([&#39;Lat&#39;,&#39;Long&#39;],axis =1).apply(lambda x: x[x &amp;gt; 0].count(), axis =0)
d = [datetime.strptime(date,&#39;%m/%d/%y&#39;).strftime(&amp;quot;%d %b&amp;quot;) for date in case_nums_country.index]

f = plt.figure(figsize=(10,5))
f.add_subplot(111)
marker_style = dict(c=&amp;quot;crimson&amp;quot;,linewidth=1, linestyle=&#39;-&#39;, marker=&#39;o&#39;,markersize=4, markerfacecolor=&#39;blue&#39;)
plt.plot(df_world.index.values, case_nums_country,**marker_style)
plt.setp(ax.get_xticklabels(), rotation=90)
plt.xlabel(&amp;quot;Dates&amp;quot;,fontsize=10)
plt.grid(alpha = 0.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_80_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.6 So sánh sự phát triển của COVID-19 theo thời gian giữa các nước&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So sánh Việt Nam, Mỹ, Nga:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_Vietnam = final_df[final_df[&#39;Country/Region&#39;] == &#39;Vietnam&#39;]
df_Russia = final_df[final_df[&#39;Country/Region&#39;] == &#39;Russia&#39;]
df_US = final_df[final_df[&#39;Country/Region&#39;] == &#39;US&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Do Mỹ và Nga cùng có số lượng các &lt;code&gt;cases&lt;/code&gt; lớn nên biểu thị vào cùng một biểu đồ:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create figure and plot space
fig, ax = plt.subplots(figsize=(12, 6))

# Add x-axis and y-axis
ax.plot(df_US[&#39;Date&#39;],
        df_US[&#39;Confirmed&#39;],
        color=&#39;blue&#39;, label = &#39;Confirmed Cases of US&#39;)

ax.plot(df_US[&#39;Date&#39;],
        df_US[&#39;Active&#39;],
        &#39;-.&#39;,
        color=&#39;blue&#39;, label = &#39;Active Cases of US&#39;)

ax.plot(df_US[&#39;Date&#39;],
        df_US[&#39;Recovered&#39;],
        &#39;--&#39;,
        color=&#39;blue&#39;, label = &#39;Recovered Cases of US&#39;)

ax.plot(df_Russia[&#39;Date&#39;],
        df_Russia[&#39;Confirmed&#39;],
        color=&#39;red&#39;, label = &#39;Confirmed Cases of Russia&#39;)

ax.plot(df_Russia[&#39;Date&#39;],
        df_Russia[&#39;Active&#39;],
        &#39;-.&#39;,
        color=&#39;red&#39;, label = &#39;Active Cases of Russia&#39;)

ax.plot(df_Russia[&#39;Date&#39;],
        df_Russia[&#39;Recovered&#39;],
        &#39;--&#39;,
        color=&#39;red&#39;, label = &#39;Recovered Cases of Russia&#39;)

# Set title and labels for axes
ax.set(xlabel=&amp;quot;Date&amp;quot;,
       ylabel=&amp;quot;Cases&amp;quot;,
       title=&amp;quot;Confirmed Cases of COVID-19 of Russia vs US&amp;quot;)

# Rotate tick marks on x-axis
plt.setp(ax.get_xticklabels(), rotation=45)
plt.legend(loc=&amp;quot;upper left&amp;quot;)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_84_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Việt nam có tổng số các &lt;code&gt;cases&lt;/code&gt; nhỏ hơn rất nhiều so với Russia và Mỹ nên nếu biểu thị vào cùng 1 biểu đồ thì sẽ rất khó nhìn. Do vậy tôi biểu diễn Việt Nam riêng:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig, ax = plt.subplots(figsize=(12, 6))

# Add x-axis and y-axis


ax.plot(df_Vietnam[&#39;Date&#39;],
        df_Vietnam[&#39;Confirmed&#39;],
        color=&amp;quot;red&amp;quot;, label = &#39;Confirmed Cases of Vietnam&#39;)

ax.plot(df_Vietnam[&#39;Date&#39;],
        df_Vietnam[&#39;Deaths&#39;],
        &#39;-.&#39;,
        color=&amp;quot;black&amp;quot;, label = &#39;Death Case of Vietnam&#39;)

ax.plot(df_Vietnam[&#39;Date&#39;],
        df_Vietnam[&#39;Active&#39;],
        &#39;-.&#39;,
        color=&amp;quot;blue&amp;quot;, label = &#39;Active Cases of Vietnam&#39;)

ax.plot(df_Vietnam[&#39;Date&#39;],
        df_Vietnam[&#39;Recovered&#39;],
        &#39;--&#39;,
        color=&amp;quot;green&amp;quot;, label = &#39;Recovered Cases of Vietnam&#39;)

# Set title and labels for axes
ax.set(xlabel=&amp;quot;Date&amp;quot;,
       ylabel=&amp;quot;Cases&amp;quot;,
       title=&amp;quot;COVID-19 cases of Vietnam&amp;quot;)

# Rotate tick marks on x-axis
plt.setp(ax.get_xticklabels(), rotation=45)
plt.legend(loc=&amp;quot;upper left&amp;quot;)
plt.grid(alpha=0.3,which=&#39;both&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_86_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Thử sử dụng jupyter notebook để viết posts cho blog. Machine Learning Project Template với Python</title>
      <link>/post/jupyter/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/post/jupyter/</guid>
      <description>&lt;p&gt;&lt;strong&gt;1. Note lại các bước để viết posts cho blog sử dụng jupyter notebook&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bước 1: Tạo Jupyter notebook&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Tạo thư mục chứa post mới
mkdir -p &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/

# chuyển đến thư mục mới tạo
cd &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/

# Tạo một jupyter notebook với tên là index
jupyter lab index.ipynb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bước 2: Tạo post metadata&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cần tạo metadata cho post  ở cell đầu tiên của jupyter notebook như sau:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: My post&#39;s title
date: 2019-09-01

# Put any other metadata here...
---
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bước 3: Convert notebook to Markdown&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.  Machine Learning Project Template với Python&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.1 Một Machine Learning Project sẽ gồm các bước cơ bản sau:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bước 1: Chuẩn bị vấn đề:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nạp các thư viện cần thiết&lt;/li&gt;
&lt;li&gt;Load tập dữ liệu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bước 2: Thăm dò dữ liệu (data exploring)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thống kê mô tả&lt;/li&gt;
&lt;li&gt;Trực quan hóa dữ liệu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bước 3. Chuẩn bị dữ liệu&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Làm sạch dữ liệu (data cleaning)&lt;/li&gt;
&lt;li&gt;Lựa chọn và biến đổi thuộc tính&lt;/li&gt;
&lt;li&gt;Chuẩn hóa dữ liệu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bước 4. Đánh giá các algorithms&lt;/p&gt;
&lt;p&gt;Bước 5. Impove accuracy&lt;/p&gt;
&lt;p&gt;Bước 6. Final model&lt;/p&gt;
&lt;h3 id=&#34;22-thực-hành-với-bài-toán-regresion&#34;&gt;2.2 Thực hành với bài toán Regresion&lt;/h3&gt;
&lt;h3 id=&#34;bước-1-chuẩn-bị-vấn-đề&#34;&gt;Bước 1. Chuẩn bị vấn đề&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Nạp các thư viện cần thiết
import numpy as np
from numpy import arange
import matplotlib.pyplot as plt
from pandas import read_csv
from pandas import set_option
#from pandas.tools.plotting import scatter_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.metrics import mean_squared_error
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Load dữ liệu
url = &#39;https://raw.githubusercontent.com/svcuong/Datasets/master/boston.csv&#39;
dataset = read_csv(url, index_col=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bước 2. Thăm dò dữ liệu&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bước 2.1: Thống kê mô tả&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Kiểm tra kích thước dữ liệu
dataset.shape
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(506, 14)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Kiểm tra kiểu dữ liệu của thuộc tính
dataset.dtypes
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;crim       float64
zn         float64
indus      float64
chas         int64
nox        float64
rm         float64
age        float64
dis        float64
rad          int64
tax          int64
ptratio    float64
black      float64
lstat      float64
medv       float64
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# hiển thị 10 hàng dữ liệu đầu tiên
print(dataset.head(10))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;       crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \
1   0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296   
2   0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242   
3   0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   
4   0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222   
5   0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222   
6   0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   
7   0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311   
8   0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   
9   0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   
10  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   

    ptratio   black  lstat  medv  
1      15.3  396.90   4.98  24.0  
2      17.8  396.90   9.14  21.6  
3      17.8  392.83   4.03  34.7  
4      18.7  394.63   2.94  33.4  
5      18.7  396.90   5.33  36.2  
6      18.7  394.12   5.21  28.7  
7      15.2  395.60  12.43  22.9  
8      15.2  396.90  19.15  27.1  
9      15.2  386.63  29.93  16.5  
10     15.2  386.71  17.10  18.9  
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# kiểm tra phân bố dữ liệu của từng thuộc tính
print(dataset.describe())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;             crim          zn       indus        chas         nox          rm  \
count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   
mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   
std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   
min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   
25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   
50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   
75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   
max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   

              age         dis         rad         tax     ptratio       black  \
count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   
mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   
std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   
min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   
25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   
50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   
75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   
max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   

            lstat        medv  
count  506.000000  506.000000  
mean    12.653063   22.532806  
std      7.141062    9.197104  
min      1.730000    5.000000  
25%      6.950000   17.025000  
50%     11.360000   21.200000  
75%     16.955000   25.000000  
max     37.970000   50.000000  
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Kiểm tra độ tương quan giữa các biến dạng numeric
print(dataset.corr(method = &#39;pearson&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;             crim        zn     indus      chas       nox        rm       age  \
crim     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   
zn      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   
indus    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   
chas    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   
nox      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   
rm      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   
age      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   
dis     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   
rad      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   
tax      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   
ptratio  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   
black   -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   
lstat    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   
medv    -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   

              dis       rad       tax   ptratio     black     lstat      medv  
crim    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  
zn       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  
indus   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  
chas    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  
nox     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  
rm       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  
age     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  
dis      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  
rad     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  
tax     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  
ptratio -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  
black    0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  
lstat   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  
medv     0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Bước 2.2: Trực quan hóa dữ liệu&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Histograms cho từng thuộc tính
dataset.hist(figsize=(12,8))
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_21_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Boxplot cho từng thuộc tính
dataset.plot(kind=&#39;box&#39;, figsize=(12,5))
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_22_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# correlation matrix
fig = plt.figure(figsize=(14, 6))
ax = fig.add_subplot(111)
cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation=&#39;none&#39;)
fig.colorbar(cax)
ticks = numpy.arange(0,14,1)
ax.set_xticks(ticks)
ax.set_yticks(ticks)
ax.set_xticklabels(names)
ax.set_yticklabels(names)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bước 3: Chuẩn bị dữ liệu&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Split-out validation dataset
array = dataset.values
X = array[:,0:13]
Y = array[:,13]
validation_size = 0.20
seed = 7
X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,
test_size=validation_size, random_state=seed)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bước 4: Đánh giá algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Test options and evaluation metric
num_folds = 10
seed = 7
scoring = &#39;neg_mean_squared_error&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Spot-Check Algorithms
models = []
models.append((&#39;LR&#39;, LinearRegression()))
models.append((&#39;LASSO&#39;, Lasso()))
models.append((&#39;EN&#39;, ElasticNet()))
models.append((&#39;KNN&#39;, KNeighborsRegressor()))
models.append((&#39;CART&#39;, DecisionTreeRegressor()))
models.append((&#39;SVR&#39;, SVR()))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import warnings
warnings.filterwarnings(&#39;ignore&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# evaluate each model in turn
results = []
names = []
for name, model in models:
    kfold = KFold(n_splits=num_folds, random_state=seed)
    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    msg = &amp;quot;%s: %f (%f)&amp;quot; % (name, cv_results.mean(), cv_results.std())
    print(msg)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;LR: -21.379856 (9.414264)
LASSO: -26.423561 (11.651110)
EN: -27.502259 (12.305022)
KNN: -41.896488 (13.901688)
CART: -26.016351 (15.164680)
SVR: -67.827886 (29.049138)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Compare Algorithms
fig = pyplot.figure(figsize=(10, 6))
fig.suptitle(&#39;Algorithm Comparison&#39;)
ax = fig.add_subplot(111)
pyplot.boxplot(results)
ax.set_xticklabels(names)
pyplot.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_31_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bước 5: Improve Results With Tuning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tôi sẽ hướng dẫn ở một bài khác&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bước 6: Finalize model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tôi sẽ hướng dẫn ở một bài khác&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Phương pháp Ensemble Learning trong Machine Learning: Boosting, Bagging, Stacking (Sử dụng R code)</title>
      <link>/post/ensemble-learning/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/post/ensemble-learning/</guid>
      <description>


&lt;p&gt;Trong &lt;code&gt;machine learning&lt;/code&gt; tồn tại định lý &lt;em&gt;“không có bữa trưa miễn phí”&lt;/em&gt; (&lt;code&gt;No free lunch theorem&lt;/code&gt;), tức là không tồn tại một thuật toán mà luôn tốt cho mọi ứng dụng và mọi tập dữ liệu, vì các thuật toán &lt;code&gt;machiner learning&lt;/code&gt; thường dựa trên một tập các tham số (&lt;code&gt;hyperparameters&lt;/code&gt;) hoặc một giả thiết nhất định nào đó về phân bố dữ liệu. Vì vậy để tìm được những thuật toán phù hợp cho tập &lt;code&gt;dataset&lt;/code&gt; của mình có thể các bạn sẽ cần nhiều thời gian để &lt;code&gt;test&lt;/code&gt; các thuật toán khác nhau. Rồi từ đó thực hiện hiệu chỉnh các tham số (&lt;code&gt;tuning hyperparameters&lt;/code&gt;) của thuật toán để thu được độ chính xác cao nhất.&lt;/p&gt;
&lt;p&gt;Một cách khác có thể sử dụng để tăng độ chính xác trên tập &lt;code&gt;dataset&lt;/code&gt; của bạn là kết hợp (&lt;code&gt;combine&lt;/code&gt;) một số mô hình với nhau. Phương pháp này gọi là &lt;code&gt;esemble learning&lt;/code&gt;. Ý tưởng của việc &lt;code&gt;combine&lt;/code&gt; các mô hình khác nhau xuất phát từ một suy nghĩ hợp lý là: các mô hình khác nhau có khả năng khác nhau, có thể thực hiện tốt nhất các loại công việc khác nhau (&lt;code&gt;subtasks&lt;/code&gt;), khi kết hợp các mô hình này với nhau một cách hợp lý thì sẽ tạo thành một mô hình kết hợp (&lt;code&gt;combined model&lt;/code&gt;) mạnh có khả năng cải thiện hiệu suât tổng thể (&lt;code&gt;overall performance&lt;/code&gt;) so với việc chỉ dùng các mô hình một cách đơn lẻ.&lt;/p&gt;
&lt;p&gt;Các phương pháp &lt;code&gt;Ensemble Learning&lt;/code&gt; được chia thành 3 loại sau đây:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Bagging&lt;/code&gt; (đóng bao)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Boosting&lt;/code&gt; (tăng cường)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stacking&lt;/code&gt; (Xếp chồng)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Trong post này, trước hết tôi sẽ giới thiệu 3 kỹ thuật &lt;code&gt;ensemble learning&lt;/code&gt; kể trên, sau đó là cách sử dụng thư viện &lt;code&gt;caret&lt;/code&gt; và &lt;code&gt;caretEnsemble&lt;/code&gt; trong &lt;code&gt;R&lt;/code&gt; để triển khai chúng và áp dụng vào bài toán cụ thể.&lt;/p&gt;
&lt;p&gt;Để cài đặt 2 thư viện này ta dùng lệnh &lt;code&gt;install.packages(.)&lt;/code&gt; với tham số đầu vào là tên thư viện muốn cài:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;caret&amp;quot;)
intall.packages(&amp;quot;caretEnsemble&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Đôi nét về thư viện caret&lt;/strong&gt;: Ngôn ngữ &lt;code&gt;R&lt;/code&gt; khác biệt bởi số lượng rất lớn các &lt;code&gt;packages&lt;/code&gt; chuyên dụng khác nhau cho phép xây dựng các mô hình dự đoán. Tuy nhiên đây cũng chính là khuyết điểm, khi có quá nhiều các gói triển khai &lt;code&gt;machine learning algorithms&lt;/code&gt; dưới dạng các
hàm &lt;code&gt;rải rác&lt;/code&gt; đòi hỏi ta cần nhiều thời gian để tìm kiếm và nắm vững những đặc trưng về cú pháp cũng như cách sử dụng của từng hàm. Để giải quyết vấn đề này &lt;a href=&#34;https://www.linkedin.com/in/max-kuhn-864a9110&#34;&gt;Max Kuhn&lt;/a&gt; đã xây dựng một giao diện phổ quát cho phép truy cập và sử dụng các &lt;code&gt;machine learning algorithms&lt;/code&gt; từ cái gói khác nhau được triển khai trên ngôn ngữ &lt;code&gt;R&lt;/code&gt;. Kết quả chính là package &lt;a href=&#34;https://cran.r-project.org/web/packages/caret/caret.pdf&#34;&gt;caret&lt;/a&gt; (viết tắt từ Classification and Regression Training), được công bố đầu tiên vào năm 2008 tại tạp chí phần mềm thống kê &lt;a href=&#34;https://www.jstatsoft.org/article/view/v028i05&#34;&gt;Journal of Statistical Software&lt;/a&gt;. Gói &lt;code&gt;caret&lt;/code&gt; giúp chúng ta tiết kiệm được rất nhiều thời gian trong quá trình phân tích và xây dựng các &lt;code&gt;models&lt;/code&gt;. Dưới đây là một số
đặc trưng cơ bản của gói &lt;code&gt;caret&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Sử dụng cú pháp lệnh chung (phổ quát) không phụ thuộc vào cú pháp của các hàm gốc (các hàm triển khai các machine learningalgorithms)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tự động tìm kiếm những giá trị tối ưu cho các &lt;code&gt;hyperparameters&lt;/code&gt; của mô hình (&lt;code&gt;tuning parameters&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Có khả năng tổ chức tính toán song song để tăng đáng kể tốc độ quá trình huấn luyện mô hình&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sử dụng &lt;code&gt;Caret&lt;/code&gt; cho phép giải quyết hầu hết các nhiệm vụ trong &lt;code&gt;machine learning&lt;/code&gt; từ tiền xủ lý cho đến đánh giá mô hình&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. Phân biệt 3 kỹ thuật boosting, baggig và statcking&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bagging&lt;/strong&gt; xây dựng một lượng lớn các &lt;code&gt;models&lt;/code&gt; (thường là &lt;code&gt;cùng loại&lt;/code&gt;) trên những &lt;code&gt;subsamples&lt;/code&gt; khác nhau từ tập &lt;code&gt;training dataset&lt;/code&gt; một cách song song nhằm đưa ra dự đoán tốt hơn.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Boosting&lt;/strong&gt; xây dựng một lượng lớn các &lt;code&gt;models&lt;/code&gt; (thường là &lt;code&gt;cùng loại&lt;/code&gt;). Tuy nhiên quá trình huấn luyện trong phương pháp này diễn ra tuần tự theo chuỗi (sequence). Trong chuỗi này mỗi &lt;code&gt;model&lt;/code&gt; sau sẽ học cách sửa những &lt;code&gt;errors&lt;/code&gt; của &lt;code&gt;model&lt;/code&gt; trước (hay nói cách khác là dữ liệu mà &lt;code&gt;model&lt;/code&gt; trước dự đoán sai).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/boosting-bagging.png&#34; alt=&#34;Nguồn ảnh&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;a href=&#34;https://www.datacamp.com/community/tutorials/adaboost-classifier-python&#34;&gt;Nguồn ảnh&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Stacking&lt;/strong&gt; xây dựng một số &lt;code&gt;models&lt;/code&gt; (thường là &lt;code&gt;khác loại&lt;/code&gt;) và một mô hình &lt;code&gt;supervisor model&lt;/code&gt;, mô hình này sẽ học cách kết hợp kết quả dự báo của một số mô hình một cách tốt nhất.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/stacking.png&#34; alt=&#34;Nguồn ảnh&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/stacking-in-machine-learning/&#34;&gt;Nguồn ảnh&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2. Thực hành&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Nạp các thư viện cần dùng vào phiên làm việc của &lt;code&gt;R&lt;/code&gt; để thực hành:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(caret)
library(caretEnsemble) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra số lượng các machine learning algorithms trong R được hỗ trợ bởi &lt;code&gt;caret&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carets &amp;lt;- getModelInfo()
carets.names &amp;lt;- names(carets)
length(carets.names)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 238&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.1 Dữ liệu để thực hành&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Để thực hành tôi lựa chọn bài toán phân loại nhị phân (&lt;code&gt;binary classification&lt;/code&gt;) với tập dữ liệu &lt;code&gt;ionoshene&lt;/code&gt;. Trong bài toán này chúng ta cần dự đoán xem cao tần trả vể từ năng lượng của các hạt trong khí quyển có cấu trúc hay là không. Để tìm hiểu thêm về bài toán này các bạn có thể đọc ở &lt;a href=&#34;http://archive.ics.uci.edu/ml/index.php&#34;&gt;đây&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Load dữ liệu từ gói &lt;code&gt;mlbench&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load the dataset
library(mlbench)
data(Ionosphere)
dataset &amp;lt;- Ionosphere&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.1.1 Thống kê mô tả (descriptive statistics)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kiểm tra kích thước tập dữ liệu:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 351  35&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra cấu trúc của tập dữ liệu:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    351 obs. of  35 variables:
##  $ V1   : Factor w/ 2 levels &amp;quot;0&amp;quot;,&amp;quot;1&amp;quot;: 2 2 2 2 2 2 2 1 2 2 ...
##  $ V2   : Factor w/ 1 level &amp;quot;0&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ V3   : num  0.995 1 1 1 1 ...
##  $ V4   : num  -0.0589 -0.1883 -0.0336 -0.4516 -0.024 ...
##  $ V5   : num  0.852 0.93 1 1 0.941 ...
##  $ V6   : num  0.02306 -0.36156 0.00485 1 0.06531 ...
##  $ V7   : num  0.834 -0.109 1 0.712 0.921 ...
##  $ V8   : num  -0.377 -0.936 -0.121 -1 -0.233 ...
##  $ V9   : num  1 1 0.89 0 0.772 ...
##  $ V10  : num  0.0376 -0.0455 0.012 0 -0.164 ...
##  $ V11  : num  0.852 0.509 0.731 0 0.528 ...
##  $ V12  : num  -0.1776 -0.6774 0.0535 0 -0.2028 ...
##  $ V13  : num  0.598 0.344 0.854 0 0.564 ...
##  $ V14  : num  -0.44945 -0.69707 0.00827 0 -0.00712 ...
##  $ V15  : num  0.605 -0.517 0.546 -1 0.344 ...
##  $ V16  : num  -0.38223 -0.97515 0.00299 0.14516 -0.27457 ...
##  $ V17  : num  0.844 0.055 0.838 0.541 0.529 ...
##  $ V18  : num  -0.385 -0.622 -0.136 -0.393 -0.218 ...
##  $ V19  : num  0.582 0.331 0.755 -1 0.451 ...
##  $ V20  : num  -0.3219 -1 -0.0854 -0.5447 -0.1781 ...
##  $ V21  : num  0.5697 -0.1315 0.7089 -0.6997 0.0598 ...
##  $ V22  : num  -0.297 -0.453 -0.275 1 -0.356 ...
##  $ V23  : num  0.3695 -0.1806 0.4339 0 0.0231 ...
##  $ V24  : num  -0.474 -0.357 -0.121 0 -0.529 ...
##  $ V25  : num  0.5681 -0.2033 0.5753 1 0.0329 ...
##  $ V26  : num  -0.512 -0.266 -0.402 0.907 -0.652 ...
##  $ V27  : num  0.411 -0.205 0.59 0.516 0.133 ...
##  $ V28  : num  -0.462 -0.184 -0.221 1 -0.532 ...
##  $ V29  : num  0.2127 -0.1904 0.431 1 0.0243 ...
##  $ V30  : num  -0.341 -0.116 -0.174 -0.201 -0.622 ...
##  $ V31  : num  0.4227 -0.1663 0.6044 0.2568 -0.0571 ...
##  $ V32  : num  -0.5449 -0.0629 -0.2418 1 -0.5957 ...
##  $ V33  : num  0.1864 -0.1374 0.5605 -0.3238 -0.0461 ...
##  $ V34  : num  -0.453 -0.0245 -0.3824 1 -0.657 ...
##  $ Class: Factor w/ 2 levels &amp;quot;bad&amp;quot;,&amp;quot;good&amp;quot;: 2 1 2 1 2 1 2 1 2 1 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hiển thị &lt;code&gt;5&lt;/code&gt; hàng dữ liệu đầu tiên:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(dataset, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   V1 V2      V3       V4      V5       V6       V7       V8      V9      V10
## 1  1  0 0.99539 -0.05889 0.85243  0.02306  0.83398 -0.37708 1.00000  0.03760
## 2  1  0 1.00000 -0.18829 0.93035 -0.36156 -0.10868 -0.93597 1.00000 -0.04549
## 3  1  0 1.00000 -0.03365 1.00000  0.00485  1.00000 -0.12062 0.88965  0.01198
## 4  1  0 1.00000 -0.45161 1.00000  1.00000  0.71216 -1.00000 0.00000  0.00000
## 5  1  0 1.00000 -0.02401 0.94140  0.06531  0.92106 -0.23255 0.77152 -0.16399
##       V11      V12     V13      V14      V15      V16     V17      V18      V19
## 1 0.85243 -0.17755 0.59755 -0.44945  0.60536 -0.38223 0.84356 -0.38542  0.58212
## 2 0.50874 -0.67743 0.34432 -0.69707 -0.51685 -0.97515 0.05499 -0.62237  0.33109
## 3 0.73082  0.05346 0.85443  0.00827  0.54591  0.00299 0.83775 -0.13644  0.75535
## 4 0.00000  0.00000 0.00000  0.00000 -1.00000  0.14516 0.54094 -0.39330 -1.00000
## 5 0.52798 -0.20275 0.56409 -0.00712  0.34395 -0.27457 0.52940 -0.21780  0.45107
##        V20      V21      V22      V23      V24      V25      V26      V27
## 1 -0.32192  0.56971 -0.29674  0.36946 -0.47357  0.56811 -0.51171  0.41078
## 2 -1.00000 -0.13151 -0.45300 -0.18056 -0.35734 -0.20332 -0.26569 -0.20468
## 3 -0.08540  0.70887 -0.27502  0.43385 -0.12062  0.57528 -0.40220  0.58984
## 4 -0.54467 -0.69975  1.00000  0.00000  0.00000  1.00000  0.90695  0.51613
## 5 -0.17813  0.05982 -0.35575  0.02309 -0.52879  0.03286 -0.65158  0.13290
##        V28      V29      V30      V31      V32      V33      V34 Class
## 1 -0.46168  0.21266 -0.34090  0.42267 -0.54487  0.18641 -0.45300  good
## 2 -0.18401 -0.19040 -0.11593 -0.16626 -0.06288 -0.13738 -0.02447   bad
## 3 -0.22145  0.43100 -0.17365  0.60436 -0.24180  0.56045 -0.38238  good
## 4  1.00000  1.00000 -0.20099  0.25682  1.00000 -0.32382  1.00000   bad
## 5 -0.53206  0.02431 -0.62197 -0.05707 -0.59573 -0.04608 -0.65697  good&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra &lt;code&gt;missing values&lt;/code&gt; trong dữ liệu:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(is.na(dataset))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra phân phối của từng thuộc tính:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  V1      V2            V3                V4                 V5         
##  0: 38   0:351   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1:313           1st Qu.: 0.4721   1st Qu.:-0.06474   1st Qu.: 0.4127  
##                  Median : 0.8711   Median : 0.01631   Median : 0.8092  
##                  Mean   : 0.6413   Mean   : 0.04437   Mean   : 0.6011  
##                  3rd Qu.: 1.0000   3rd Qu.: 0.19418   3rd Qu.: 1.0000  
##                  Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##        V6                V7                V8                 V9          
##  Min.   :-1.0000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.00000  
##  1st Qu.:-0.0248   1st Qu.: 0.2113   1st Qu.:-0.05484   1st Qu.: 0.08711  
##  Median : 0.0228   Median : 0.7287   Median : 0.01471   Median : 0.68421  
##  Mean   : 0.1159   Mean   : 0.5501   Mean   : 0.11936   Mean   : 0.51185  
##  3rd Qu.: 0.3347   3rd Qu.: 0.9692   3rd Qu.: 0.44567   3rd Qu.: 0.95324  
##  Max.   : 1.0000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.00000  
##       V10                V11                V12                V13         
##  Min.   :-1.00000   Min.   :-1.00000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.04807   1st Qu.: 0.02112   1st Qu.:-0.06527   1st Qu.: 0.0000  
##  Median : 0.01829   Median : 0.66798   Median : 0.02825   Median : 0.6441  
##  Mean   : 0.18135   Mean   : 0.47618   Mean   : 0.15504   Mean   : 0.4008  
##  3rd Qu.: 0.53419   3rd Qu.: 0.95790   3rd Qu.: 0.48237   3rd Qu.: 0.9555  
##  Max.   : 1.00000   Max.   : 1.00000   Max.   : 1.00000   Max.   : 1.0000  
##       V14                V15               V16                V17         
##  Min.   :-1.00000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.07372   1st Qu.: 0.0000   1st Qu.:-0.08170   1st Qu.: 0.0000  
##  Median : 0.03027   Median : 0.6019   Median : 0.00000   Median : 0.5909  
##  Mean   : 0.09341   Mean   : 0.3442   Mean   : 0.07113   Mean   : 0.3819  
##  3rd Qu.: 0.37486   3rd Qu.: 0.9193   3rd Qu.: 0.30897   3rd Qu.: 0.9357  
##  Max.   : 1.00000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V18                 V19               V20                V21         
##  Min.   :-1.000000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.225690   1st Qu.: 0.0000   1st Qu.:-0.23467   1st Qu.: 0.0000  
##  Median : 0.000000   Median : 0.5762   Median : 0.00000   Median : 0.4991  
##  Mean   :-0.003617   Mean   : 0.3594   Mean   :-0.02402   Mean   : 0.3367  
##  3rd Qu.: 0.195285   3rd Qu.: 0.8993   3rd Qu.: 0.13437   3rd Qu.: 0.8949  
##  Max.   : 1.000000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V22                 V23               V24                V25         
##  Min.   :-1.000000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.243870   1st Qu.: 0.0000   1st Qu.:-0.36689   1st Qu.: 0.0000  
##  Median : 0.000000   Median : 0.5318   Median : 0.00000   Median : 0.5539  
##  Mean   : 0.008296   Mean   : 0.3625   Mean   :-0.05741   Mean   : 0.3961  
##  3rd Qu.: 0.188760   3rd Qu.: 0.9112   3rd Qu.: 0.16463   3rd Qu.: 0.9052  
##  Max.   : 1.000000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V26                V27               V28                V29         
##  Min.   :-1.00000   Min.   :-1.0000   Min.   :-1.00000   Min.   :-1.0000  
##  1st Qu.:-0.33239   1st Qu.: 0.2864   1st Qu.:-0.44316   1st Qu.: 0.0000  
##  Median :-0.01505   Median : 0.7082   Median :-0.01769   Median : 0.4966  
##  Mean   :-0.07119   Mean   : 0.5416   Mean   :-0.06954   Mean   : 0.3784  
##  3rd Qu.: 0.15676   3rd Qu.: 0.9999   3rd Qu.: 0.15354   3rd Qu.: 0.8835  
##  Max.   : 1.00000   Max.   : 1.0000   Max.   : 1.00000   Max.   : 1.0000  
##       V30                V31               V32                 V33         
##  Min.   :-1.00000   Min.   :-1.0000   Min.   :-1.000000   Min.   :-1.0000  
##  1st Qu.:-0.23689   1st Qu.: 0.0000   1st Qu.:-0.242595   1st Qu.: 0.0000  
##  Median : 0.00000   Median : 0.4428   Median : 0.000000   Median : 0.4096  
##  Mean   :-0.02791   Mean   : 0.3525   Mean   :-0.003794   Mean   : 0.3494  
##  3rd Qu.: 0.15407   3rd Qu.: 0.8576   3rd Qu.: 0.200120   3rd Qu.: 0.8138  
##  Max.   : 1.00000   Max.   : 1.0000   Max.   : 1.000000   Max.   : 1.0000  
##       V34            Class    
##  Min.   :-1.00000   bad :126  
##  1st Qu.:-0.16535   good:225  
##  Median : 0.00000             
##  Mean   : 0.01448             
##  3rd Qu.: 0.17166             
##  Max.   : 1.00000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thuộc tính thứ &lt;code&gt;V2&lt;/code&gt; chỉ có 1 giá trị là &lt;code&gt;0&lt;/code&gt; nên có thể loại bỏ:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset$V2 &amp;lt;- NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chuyển thuộc tính &lt;code&gt;V1&lt;/code&gt; từ &lt;code&gt;factor&lt;/code&gt; sang &lt;code&gt;numeric&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset$V1 &amp;lt;- as.numeric(as.character(dataset$V1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra mức độ tương quan (&lt;code&gt;correlation&lt;/code&gt;) giữa các thuộc tính (do số lượng thuộc tính lớn nên tôi chỉ hiển thị tương quan giữa 6 thuộc tính đầu làm mẫu):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(dataset[,1:6])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              V1         V3           V4         V5          V6          V7
## V1  1.000000000 0.30203392 -0.006528852 0.15615240  0.12760571  0.22186692
## V3  0.302033923 1.00000000  0.143364804 0.47658695  0.02576751  0.44025437
## V4 -0.006528852 0.14336480  1.000000000 0.00115185 -0.19030761 -0.05402953
## V5  0.156152397 0.47658695  0.001151850 1.00000000  0.03832312  0.59707508
## V6  0.127605707 0.02576751 -0.190307607 0.03832312  1.00000000 -0.01022692
## V7  0.221866916 0.44025437 -0.054029528 0.59707508 -0.01022692  1.00000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.1.2 Trực quan hóa dữ liệu (&lt;code&gt;data visualization&lt;/code&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Do số lượng thuộc tính nhiều nên tôi chỉ thực hiện &lt;code&gt;data visualization&lt;/code&gt; đối 12 thuộc tính đầu của tập dữ liệu.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Histogram&lt;/code&gt; cho 12 thuộc tính đầu:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow=c(3,4))
for(i in 1:12) { 
  hist(dataset[,i], main=names(dataset)[i], breaks = 30)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ensemble-learning/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Boxplot&lt;/code&gt; cho 12 thuộc tính đầu:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boxplot(dataset[, 1:12], col = &amp;quot;orange&amp;quot;, main = &amp;quot;Features Boxplot&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ensemble-learning/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trong bước này nếu phát hiện trong các thuộc tính có nhiều giá trị ngoại lai (&lt;code&gt;outliers&lt;/code&gt;) thì các bạn có thể đọc post trước của tôi về cách loại bỏ &lt;code&gt;outliers&lt;/code&gt; trong dữ liệu cho &lt;code&gt;machine learning&lt;/code&gt; bằng các phương pháp thống kê tại &lt;a href=&#34;https://svcuong.github.io/post/remove-outliers/&#34;&gt;đây&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.1.3 Tiền xử lý dữ liệu (&lt;code&gt;data preprocessing&lt;/code&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Xác định và Loại bỏ các thuộc tính tương quan với nhau cao (&amp;gt;0.75)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Tìm các thuộc tính tương quan với nhau cao
cor_coefficient &amp;lt;- 0.75
correlations &amp;lt;- cor(dataset[,1:13])
highlyCorrelated &amp;lt;- findCorrelation(correlations, cutoff=cor_coefficient)
length(highlyCorrelated)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ở đây không có các thuộc tính tương quan cao với nhau, tuy nhiên nếu có thì các bạn có thể loại bỏ chúng như sau:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasetFeatures &amp;lt;- dataset[,-highlyCorrelated]
dim(datasetFeatures)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chuẩn hóa giá trị của các thuộc tính (&lt;code&gt;data normalization&lt;/code&gt;) về khoảng &lt;code&gt;[0,1]&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;preProcValues &amp;lt;- preProcess(dataset, method = c(&amp;quot;range&amp;quot;))
data_processed &amp;lt;- predict(preProcValues, dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vậy là dữ liệu của chúng ta đã sẵn sàng để &lt;code&gt;test&lt;/code&gt; các thuật toán &lt;code&gt;ensemble learning&lt;/code&gt; rồi.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.2. Thuật toán Boosting&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Trong phạm vi post này tôi sẽ test hai thuật toán &lt;code&gt;boosting&lt;/code&gt; khá phổ biến là: &lt;code&gt;C5.0&lt;/code&gt; và &lt;code&gt;Stochastic Gradient Boosting&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Dưới đây là ví dụ huấn luyện hai mô hình này trên &lt;code&gt;R&lt;/code&gt; với các tham số mặc định:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seed &amp;lt;- 10
# tạo một đối tượng control cho cross-validation
control &amp;lt;- trainControl(method=&amp;quot;repeatedcv&amp;quot;, number=10, repeats=3)
# Trong đó
# method = &amp;#39;repeatedcv&amp;#39;: sử dụng cross-validation với các tham số sau:
# number = 10 có nhĩa là quá trình cross-validation cần chia dữ liệu gốc thành 10 phần bằng nhau
# repeats = 3 có nhĩa là quá trình cross-validation sẽ hoàn thành sau 3 lần

# C5.0
set.seed(seed)
fit.c50 &amp;lt;- train(Class~., data=dataset, method=&amp;quot;C5.0&amp;quot;, metric = &amp;quot;Accuracy&amp;quot;, trControl=control)

# Stochastic Gradient Boosting
set.seed(seed)
fit.gbm &amp;lt;- train(Class~., data=dataset, method=&amp;quot;gbm&amp;quot;, metric = &amp;quot;Accuracy&amp;quot;, trControl=control, verbose=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So sánh kết quả hai mô hình:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boosting_results &amp;lt;- resamples(list(c5.0=fit.c50, gbm=fit.gbm))
summary(boosting_results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = boosting_results)
## 
## Models: c5.0, gbm 
## Number of resamples: 30 
## 
## Accuracy 
##           Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&amp;#39;s
## c5.0 0.8823529 0.9148810 0.9575163 0.9468627 0.9714286    1    0
## gbm  0.8529412 0.9166667 0.9428571 0.9420184 0.9714286    1    0
## 
## Kappa 
##           Min.   1st Qu.    Median      Mean  3rd Qu. Max. NA&amp;#39;s
## c5.0 0.7213115 0.8157164 0.9069808 0.8806722 0.937833    1    0
## gbm  0.6586345 0.8142060 0.8776224 0.8707906 0.937201    1    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dotplot(boosting_results)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ensemble-learning/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Từ kết quả so sánh ta thấy thuật toán &lt;code&gt;C5.0&lt;/code&gt; cho kết quả chính xác hơn so với &lt;code&gt;Stochastic Gradient Boosting&lt;/code&gt; trong bài toán này (với độ chính xác là &lt;code&gt;94.68%&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.3 Thuật toán Bagging&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Chúng ta cùng test hai thuật toán thuộc kỹ thuật &lt;code&gt;Bagging&lt;/code&gt; là: &lt;code&gt;Bagged CART&lt;/code&gt; và &lt;code&gt;Random Forest&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Dưới đây là ví dụ huấn luyện hai mô hình này trên &lt;code&gt;R&lt;/code&gt; với các tham số mặc định:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;control &amp;lt;- trainControl(method=&amp;quot;repeatedcv&amp;quot;, number=10, repeats=3)

# Bagged CART
set.seed(seed)
fit.treebag &amp;lt;- train(Class~., data=dataset, method=&amp;quot;treebag&amp;quot;, metric = &amp;quot;Accuracy&amp;quot;, trControl=control)

# Random Forest
set.seed(seed)
fit.rf &amp;lt;- train(Class~., data=dataset, method=&amp;quot;rf&amp;quot;, metric = &amp;quot;Accuracy&amp;quot;, trControl=control)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So sánh kết quả hai mô hình:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bagging_results &amp;lt;- resamples(list(treebag=fit.treebag, rf=fit.rf))
summary(bagging_results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = bagging_results)
## 
## Models: treebag, rf 
## Number of resamples: 30 
## 
## Accuracy 
##              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&amp;#39;s
## treebag 0.8285714 0.8922269 0.9428571 0.9210566 0.9440476 0.9722222    0
## rf      0.8235294 0.9142857 0.9428571 0.9343946 0.9714286 1.0000000    0
## 
## Kappa 
##              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&amp;#39;s
## treebag 0.6209386 0.7708291 0.8731884 0.8266350 0.8770749 0.9407895    0
## rf      0.5984252 0.8149436 0.8734173 0.8550575 0.9372010 1.0000000    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dotplot(bagging_results)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ensemble-learning/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Từ kết quả so sánh ta thấy thuật toán &lt;code&gt;Random Forest&lt;/code&gt; cho kết quả chính xác hơn so với &lt;code&gt;CART&lt;/code&gt; trong bài toán này (với độ chính xác là &lt;code&gt;93.44%&lt;/code&gt;). Tuy nhiên cả hai thuật toán &lt;code&gt;Bagging&lt;/code&gt; đều có độ chính xác nhỏ hơn so với 2 thuật toán &lt;code&gt;Boosting&lt;/code&gt; trước.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.4. Thuật toán Stacking&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Để kết hợp các mô hình &lt;code&gt;machine learning&lt;/code&gt; khác nhau trong &lt;code&gt;R&lt;/code&gt; chúng ta sử dụng thư viện &lt;strong&gt;caretEnsemble&lt;/strong&gt;. Với danh sách các &lt;code&gt;caret models&lt;/code&gt;, hàm &lt;code&gt;caretStack()&lt;/code&gt; của gói này có thể sự dụng để chỉ định mô hình bậc cao hơn, từ đó sẽ học cách tìm sự kết hợp tốt nhất những &lt;code&gt;sub-models&lt;/code&gt; với nhau.&lt;/p&gt;
&lt;p&gt;Ở ví dụ này, tôi sẽ sử dụng 5 &lt;code&gt;sub-models&lt;/code&gt; sau cho tập dữ liệu &lt;code&gt;ionosphere&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear Discriminate Analysis (&lt;code&gt;LDA&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Classification and Regression Trees (&lt;code&gt;CART&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Logistic Regression (&lt;code&gt;GLM&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;k-Nearest Neighbors (&lt;code&gt;kNN&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Support Vector Machine with a Radial Basis Kernel Function (&lt;code&gt;SVM&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dưới đây là ví dụ huấn luyện 5 mô hình này trên &lt;code&gt;R&lt;/code&gt; với các tham số mặc định:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;control &amp;lt;- trainControl(method=&amp;quot;repeatedcv&amp;quot;, number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
algorithmList &amp;lt;- c(&amp;#39;lda&amp;#39;, &amp;#39;rpart&amp;#39;, &amp;#39;glm&amp;#39;, &amp;#39;knn&amp;#39;, &amp;#39;svmRadial&amp;#39;)
set.seed(seed)
models &amp;lt;- caretList(Class~., data=dataset, trControl=control, methodList=algorithmList)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So sánh kết quả các mô hình:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- resamples(models)
summary(results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = results)
## 
## Models: lda, rpart, glm, knn, svmRadial 
## Number of resamples: 30 
## 
## Accuracy 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&amp;#39;s
## lda       0.7941176 0.8297619 0.8571429 0.8669546 0.9136555 0.9428571    0
## rpart     0.8000000 0.8529412 0.8611111 0.8736819 0.9079365 0.9714286    0
## glm       0.7428571 0.8539916 0.8823529 0.8824214 0.9166667 0.9714286    0
## knn       0.7500000 0.8235294 0.8333333 0.8403097 0.8601190 0.9444444    0
## svmRadial 0.8888889 0.9142857 0.9436508 0.9477591 0.9714286 1.0000000    0
## 
## Kappa 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&amp;#39;s
## lda       0.4803493 0.6048824 0.6697323 0.6868903 0.8032314 0.8679245    0
## rpart     0.5648313 0.6586345 0.7024010 0.7193438 0.7900135 0.9397590    0
## glm       0.4578313 0.6618591 0.7267975 0.7371380 0.8163265 0.9368030    0
## knn       0.4087591 0.5641026 0.6196004 0.6199654 0.6770575 0.8754325    0
## svmRadial 0.7419355 0.8142060 0.8776224 0.8847121 0.9375755 1.0000000    0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dotplot(results)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ensemble-learning/index_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ta thấy trong các mô hình này thì &lt;code&gt;SVM&lt;/code&gt; cho kết quả chính xác nhất (&lt;code&gt;94.78%&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Giờ chúng ta hãy thử dùng kỹ thuật &lt;code&gt;stacking&lt;/code&gt; để xem có thể cải thiện được độ chính xác không.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Lưu ý&lt;/code&gt;:&lt;/strong&gt; Khi các bạn muốn kết hợp các mô hình với nhau sử dụng kỹ thuật &lt;code&gt;stacking&lt;/code&gt;, thì các bạn cần kiểm chứng rằng kết quả dự báo từ các mô hình này tương quan với nhau thấp. Nếu kết quả dự báo của các &lt;code&gt;sub-models&lt;/code&gt; tương quan cao với nhau (&amp;gt; 0.75) thì có nghĩa là chúng sẽ cho kết quả dự báo tương tự nhau, điều này sẽ làm giảm hiệu quả khi ta kết hợp các mô hình này với nhau.&lt;/p&gt;
&lt;p&gt;Kiểm tra độ tương quan giữa các &lt;code&gt;sub-models&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelCor(results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 lda       rpart         glm       knn svmRadial
## lda       1.0000000 0.379461533 0.277037721 0.4898435 0.3056838
## rpart     0.3794615 1.000000000 0.001889458 0.4040556 0.2539580
## glm       0.2770377 0.001889458 1.000000000 0.1466240 0.4296011
## knn       0.4898435 0.404055597 0.146623958 1.0000000 0.5495574
## svmRadial 0.3056838 0.253957967 0.429601141 0.5495574 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;splom(results)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ensemble-learning/index_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nhìn vào kết quả ta có thể thấy các &lt;code&gt;su-models&lt;/code&gt; cho kết quả dự báo tương quan với nhau thấp theo từng cặp. Cặp tương quan với nhau nhất là &lt;code&gt;SVM&lt;/code&gt; và &lt;code&gt;kNN&lt;/code&gt; với độ tương quan &lt;code&gt;0.549&lt;/code&gt;, cũng vẫn nhỏ hơn mức quy địn là cao (&lt;code&gt;&amp;gt;0.75&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Nào chúng ta hãy thử kết hợp &lt;code&gt;predictions&lt;/code&gt; của các &lt;code&gt;sub-models&lt;/code&gt; sử dụng mô hình &lt;code&gt;gml&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stackControl &amp;lt;- trainControl(method=&amp;quot;repeatedcv&amp;quot;, number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
set.seed(seed)
stack.glm &amp;lt;- caretStack(models, method=&amp;quot;glm&amp;quot;, metric=&amp;quot;Accuracy&amp;quot;, trControl=stackControl)
print(stack.glm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## A glm ensemble of 5 base models: lda, rpart, glm, knn, svmRadial
## 
## Ensemble results:
## Generalized Linear Model 
## 
## 1053 samples
##    5 predictor
##    2 classes: &amp;#39;bad&amp;#39;, &amp;#39;good&amp;#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 947, 947, 947, 948, 947, 949, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.9544285  0.9003902&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Độ chính xác cải thiện lên &lt;code&gt;95.44%&lt;/code&gt; so với chỉ sử dụng &lt;code&gt;SVM model&lt;/code&gt; là &lt;code&gt;94.78%&lt;/code&gt;, tuy nhiên cũng chưa có độ chênh lệnh nhiều.&lt;/p&gt;
&lt;p&gt;Tiếp theo tôi thử thử kết hợp &lt;code&gt;predictions&lt;/code&gt; của các &lt;code&gt;sub-models&lt;/code&gt; sử dụng mô hình &lt;code&gt;random forest&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(seed)
stack.rf &amp;lt;- caretStack(models, method=&amp;quot;rf&amp;quot;, metric=&amp;quot;Accuracy&amp;quot;, trControl=stackControl)
print(stack.rf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## A rf ensemble of 5 base models: lda, rpart, glm, knn, svmRadial
## 
## Ensemble results:
## Random Forest 
## 
## 1053 samples
##    5 predictor
##    2 classes: &amp;#39;bad&amp;#39;, &amp;#39;good&amp;#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 947, 947, 947, 948, 947, 949, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   2     0.9623381  0.9177343
##   3     0.9588700  0.9103978
##   5     0.9569833  0.9064705
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 2.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Độ chính xác cũng cải thiện hơn so với chỉ dùng &lt;code&gt;svm model&lt;/code&gt; (&lt;code&gt;96.23%&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tham khảo:&lt;/strong&gt;
&lt;a href=&#34;https://machinelearningmastery.com/machine-learning-ensembles-with-r/&#34;&gt;How to Build an Ensemble Of Machine Learning Algorithms in R&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sử dụng thống kê để xác định và loại bỏ dữ liệu ngoại lai cho machine learning trong R và Python</title>
      <link>/post/remove-outliers/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/post/remove-outliers/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://leadupcollective.org/2017/06/02/statistics-high-performers-studying-the-outliers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nguồn ảnh&lt;/a&gt;
&lt;img src=&#34;/img/outliers1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Outliers (dữ liệu ngoại lai hay là nhiễu) là một trong những thuật ngữ được sử dụng rất rộng rãi trong thế giới data science. Trong quá trình xây dựng các mô hình dự đoán, việc xác định và loại bỏ outliers trong dữ liệu là một bước vô cùng quan trọng. Nó giúp tăng cao độ chính xác cho các mô hình dự đoán.&lt;/p&gt;
&lt;p&gt;Khi phân tích, chúng ta thường dùng các tham số như là &lt;code&gt;mean&lt;/code&gt;, &lt;code&gt;median&lt;/code&gt; và &lt;code&gt;mode&lt;/code&gt; để biết xu hướng tập trung của dữ liệu. Tuy nhiên, một câu hỏi quan trọng cần phải trả lời khi xem xét chất lượng của một mẫu dữ liệu trong  phân tích  đó là &lt;em&gt;&amp;ldquo;làm sao để đo được độ biến động (hay độ phân tán) của mẫu dữ liệu đó&amp;rdquo;?&lt;/em&gt;.  Vì chúng ta có thể có 2 mẫu dữ liệu với cùng giá trị &lt;code&gt;mean&lt;/code&gt; nhưng độ biến động của chúng lại hoàn toàn khác nhau. Trong thống kê những đại lượng phổ biến nhất để đo lường tiêu chí này là khoảng phần tư (interquartile range, &lt;code&gt;IQR&lt;/code&gt;) (hay còn được gọi là khoảng cách giữa các tứ phân vị), phương sai (&lt;code&gt;variance&lt;/code&gt;) và độ lệch chuẩn (standard deviation, &lt;code&gt;STD&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Ở post này tôi sẽ giới thiệu với các bạn cách sử dụng 2 phương pháp thống kê trong R và Python để xác định và loại bỏ outliers trong dữ liệu đó là:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;STD&lt;/code&gt; có thể sử dụng để xác định outliers trong dữ liệu có dạng/gần như dạng phân phối chuẩn (hay còn gọi là phân phối &lt;code&gt;Gauss&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;IQR&lt;/code&gt; có thể sử dụng để xác định và loại bỏ outliers không phụ thuộc vào dạng phân phối của dữ liệu.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Và ở cuối post tôi sẽ hướng dẫn các bạn viết hàm tự động xác định và loại bỏ outliers từ dữ liệu sử dụng hai phương pháp trên.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;1. Tạo dữ liệu  để thực hành&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Để thực hành tôi sử dụng hàm mô phỏng phân phối chuẩn &lt;code&gt;rnorm()&lt;/code&gt; trong R để tạo ra dãy số ngẫu nhiên gồm &lt;code&gt;5000&lt;/code&gt; số với các tham số giá trị trung bình là &lt;code&gt;20&lt;/code&gt; và độ lệnh chuẩn là &lt;code&gt;2&lt;/code&gt; như sau:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
data = rnorm(5000, mean = 20, sd = 2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Với Python thì ta thực hiện như sau:&lt;/p&gt;
&lt;p&gt;Trước hết cần nạp thư viện &lt;code&gt;reticulate&lt;/code&gt; để sử dụng Python trong R:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
library(reticulate)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cụ thể về cách sử dụng thư viện &lt;code&gt;reticulate&lt;/code&gt; để kết hợp R và Python tôi đã giới thiệu ở post trước, các bạn có thể đọc ở 
&lt;a href=&#34;https://svcuong.github.io/post/s-d-ng-k-t-h-p-r-va-python-trong-data-science/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;đây&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tạo dữ liệu trong python:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
# Tạo dữ liệu tương tự như trong R
from numpy.random import randn
data = 2* randn(5000) + 20
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Trong dữ liệu được tạo ra từ phân phối chuẩn sẽ có một số giá trị nằm cách xa giá trị trung bình &lt;code&gt;mean&lt;/code&gt; mà chúng ta có thể xác định là &lt;code&gt;outliers&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Biểu diễn dữ liệu bằng histogam sử dụng hàm &lt;code&gt;hist()&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
hist(data, breaks= 60, main=&amp;quot;Histogram With breaks=60&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-08-19-remove-outliers.vn_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nhân tiện đây tôi cũng xin giới thiệu một số hàm hỗ trợ cho các tính toán thống kê trong R như: &lt;code&gt;summary()&lt;/code&gt;, &lt;code&gt;sample()&lt;/code&gt;, &lt;code&gt;dnorm()&lt;/code&gt;, &lt;code&gt;pnorm()&lt;/code&gt;, &lt;code&gt;qnorm()&lt;/code&gt;, &lt;code&gt;dunif()&lt;/code&gt;, &lt;code&gt;punif()&lt;/code&gt;, &lt;code&gt;qunif()&lt;/code&gt;, &lt;code&gt;runif()&lt;/code&gt;, &lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;sd()&lt;/code&gt;, &lt;code&gt;cov()&lt;/code&gt;, &lt;code&gt;cor()&lt;/code&gt;,&amp;hellip;&lt;/p&gt;
&lt;p&gt;Hàm &lt;code&gt;summay()&lt;/code&gt; cho phép thực hiện thống kê mô tả (&lt;code&gt;descriptive statistics&lt;/code&gt;) để cung cấp cho chúng ta một số thông tin thống kê cơ bản về một biến số:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
summary(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   12.84   18.66   19.99   20.00   21.37   26.96
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ví dụ sử dụng hàm &lt;code&gt;sample()&lt;/code&gt; để tạo mẫu ngẫu nhiên có lặp lại 10 số nguyên từ 0 đến 9:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
sample(0:9, replace = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 8 7 4 3 1 6 9 5 3 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ví dụ sử dụng hàm tính mật độ phân phối chuẩn &lt;code&gt;dnorm()&lt;/code&gt; để ước tính xác xuất của học sinh có điểm là &lt;code&gt;16.5&lt;/code&gt;  biết rằng điểm của học sinh tuân theo phân phối chuẩn với giá trị trung bình là &lt;code&gt;15&lt;/code&gt;, độ lệnh chuẩn là &lt;code&gt;2.5&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
dnorm(16.5, mean = 15, sd = 2.5)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1332898
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tiếp theo ví dụ trên để ước tính xác suất học sinh có điểm tối thiểu là
&lt;code&gt;16.5&lt;/code&gt;, ta có thể sử dụng hàm tính xác suất chuẩn tích lũy &lt;code&gt;pnorm()&lt;/code&gt; như sau:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
1 - pnorm(16.5, mean = 15, sd = 2.5)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2742531
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chức năng của các hàm R còn lại  cũng như các hàm tương tự trong Python các bạn có thể tự tìm hiểu thêm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Phương pháp STD&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Nếu như biết được rằng dữ liệu có dạng phân phối &lt;code&gt;Gauss&lt;/code&gt; thì chúng ta có thể sử dụng STD trong vài trò là thước đo giới hạn độ phân tán của dữ liệu để xác định outliers.&lt;/p&gt;
&lt;p&gt;Trong phân phối &lt;code&gt;Gauss&lt;/code&gt; dựa vào giá trị trung bình &lt;code&gt;mean&lt;/code&gt; và &lt;code&gt;STD&lt;/code&gt; cho phép chúng ta kiểm tra được độ phân tán (hay là phần trăm bao phủ) của dữ liệu đó như thế nào. Ví dụ:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Độ bao phủ với &lt;code&gt;1 STD&lt;/code&gt; từ mean là &lt;code&gt;68%&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Độ bao phủ với &lt;code&gt;2 STD&lt;/code&gt; từ mean là &lt;code&gt;95%&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Độ bao phủ với &lt;code&gt;3 STD&lt;/code&gt; từ mean là &lt;code&gt;99.7%&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-08-19-remove-outliers.vn_files/std.jpg&#34; alt=&#34;&#34;&gt;

&lt;a href=&#34;https://www.students4bestevidence.net/blog/2018/09/26/a-beginners-guide-to-standard-deviation-and-standard-error/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nguồn ảnh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vậy nên với dữ liệu dạng &lt;code&gt;Gauss&lt;/code&gt; có độ phân tán bình thường thì với &lt;code&gt;3STD&lt;/code&gt;, chúng ta sẽ bao phủ được khoảng &amp;gt; &lt;code&gt;99%&lt;/code&gt; của dữ liệu. Từ đó những điểm dữ liệu nằm ngoài &lt;code&gt;3STD&lt;/code&gt; sẽ được coi là outliers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Các bước xác định outliers bằng phương pháp &lt;code&gt;STD&lt;/code&gt; như sau:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bước 1: Tính &lt;code&gt;mean&lt;/code&gt; và &lt;code&gt;std&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# tính mean và std
# R
mean_data &amp;lt;- mean(data)
std_data &amp;lt;- sd(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
from numpy import mean
from numpy import std
mean_data, std_data = mean(data), std(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bước 2: Tính giá trị biên &lt;code&gt;Upper/Lower&lt;/code&gt; để xác định &lt;code&gt;outliers&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# thiết lập giới hạn để xác định outliers
# R
limit_std = 3*std_data
lower_std = mean_data - limit_std
upper_std = mean_data + limit_std
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
limit_std = 3*std_data
lower_std, upper_std = mean_data - limit_std, mean_data + limit_std
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bước 3: Xác định và loại bỏ &lt;code&gt;outliers&lt;/code&gt; dựa trên giá trị biên&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# xác định outliers
# R
ouliers_index_std &amp;lt;- which(data &amp;gt; upper_std | data &amp;lt; lower_std)
print(paste(&amp;quot;Number of outliers:&amp;quot;, length(ouliers_index_std)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Number of outliers: 16&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
ouliers_index_std = [x for x in data if x &amp;lt; lower_std or x &amp;gt; upper_std]
print(&#39;Number of outliers: %d&#39; % len(ouliers_index_std))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of outliers: 14
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Loại bỏ outliers
# R
data_new_std &amp;lt;- data[-ouliers_index_std]
print(paste(&amp;quot;Number of Non-outliers:&amp;quot;, length(data_new_std)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Number of Non-outliers: 4984&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
data_new_std = [x for x in data if x &amp;gt;= lower_std and x &amp;lt;= upper_std]
print(&#39;Number of Non-outliers:: %d&#39; % len(data_new_std))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of Non-outliers:: 4986
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2. Phương pháp &lt;code&gt;IQR&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tứ phân vị là đại lượng mô tả sự phân bố và sự phân tán của tập dữ liệu. Tứ phân vị có &lt;code&gt;3&lt;/code&gt; giá trị, đó là tứ phân vị thứ nhất &lt;code&gt;Q1&lt;/code&gt; (25th), thứ hai &lt;code&gt;Q2&lt;/code&gt; (50th) hay &lt;code&gt;median&lt;/code&gt;, và thứ ba &lt;code&gt;Q3&lt;/code&gt; (75th). Ba giá trị này chia một tập hợp dữ liệu (đã sắp xếp dữ liệu theo trật từ từ bé đến lớn) thành &lt;code&gt;4&lt;/code&gt; phần có số lượng quan sát đều nhau. Tứ phân vị được xác định như sau:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sắp xếp các số theo thứ tự tăng dần&lt;/li&gt;
&lt;li&gt;Cắt dãy số thành &lt;code&gt;4&lt;/code&gt; phàn bằng nhau&lt;/li&gt;
&lt;li&gt;Tứ phân vị là các giá trị tại vị trí cắt&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-08-19-remove-outliers.vn_files/IQR.png&#34; alt=&#34;&#34;&gt;

&lt;a href=&#34;https://medium.com/@dhwajraj/learning-python-regression-analysis-part-7-handling-outliers-in-data-d36ee9e2130b&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nguồn ảnh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IQR&lt;/code&gt; là sự khác biệt giữa tứ phân vị thứ nhất &lt;code&gt;Q1&lt;/code&gt; và tứ phân vị thứ ba &lt;code&gt;Q3&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$IQR = Q_3 - Q_1$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Giá trị &lt;code&gt;IQR&lt;/code&gt; có thể sử dụng để xác định &lt;code&gt;outliers&lt;/code&gt; bằng cách thiết lập các giá trị biên &lt;code&gt;Upper/Lower&lt;/code&gt; giống với phương pháp &lt;code&gt;STD&lt;/code&gt; như sau:  Nếu chúng ta trừ đi &lt;code&gt;kxIQR&lt;/code&gt; từ tứ phân vị đầu tiên &lt;code&gt;Q1&lt;/code&gt;, bất kỳ giá trị dữ liệu nào nhỏ hơn con số này được coi là giá trị outliers. Tương tự như vậy, nếu chúng ta thêm &lt;code&gt;kxIQR&lt;/code&gt; đến tứ phân vị thứ ba &lt;code&gt;Q3&lt;/code&gt;, bất kỳ giá trị dữ liệu nào lớn hơn con số này được coi là outliers. Giá trị &lt;code&gt;k&lt;/code&gt;  thường được chọn là &lt;code&gt;1.5&lt;/code&gt;. Trong trường hợp xác định các &lt;code&gt;extreme outliers&lt;/code&gt; có thể dùng giá trị &lt;code&gt;k = 3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Các bước xác định &lt;code&gt;outliers&lt;/code&gt; bằng phương pháp &lt;code&gt;IQR&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bước 1: Tính &lt;code&gt;IQR&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Tính IQR
# R
q25 &amp;lt;- quantile(data, 0.25)
q75 &amp;lt;- quantile(data, 0.75)
iqr &amp;lt;- q75 - q25
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
import numpy as np
q25, q75 = np.percentile(data, 25), np.percentile(data, 75)
iqr = q75 - q25
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bước 2: Tính giá trị biên &lt;code&gt;Upper/Lower&lt;/code&gt; để xác định &lt;code&gt;outliers&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# thiết lập giới hạn để xác định outliers
# R
limit_iqr = 1.5*iqr
lower_iqr = q25 - limit_iqr
upper_iqr = q75 + limit_iqr
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
limit_iqr = 1.5*iqr
lower_iqr, upper_iqr = q25 - limit_iqr, q75 + limit_iqr
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bước 3: Xác định và loại bỏ &lt;code&gt;outliers&lt;/code&gt; dựa trên giá trị biên&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# xác định outliers
# R
ouliers_index_iqr &amp;lt;- which(data &amp;gt; upper_iqr | data &amp;lt; lower_iqr)
print(paste(&amp;quot;Number of outliers:&amp;quot;, length(ouliers_index_iqr)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Number of outliers: 30&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
ouliers_index_iqr = [x for x in data if x &amp;lt; lower_iqr or x &amp;gt; upper_iqr]
print(&#39;Number of outliers: %d&#39; % len(ouliers_index_iqr))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of outliers: 35
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Loại bỏ outliers
# R
data_new_iqr &amp;lt;- data[-ouliers_index_iqr]
print(paste(&amp;quot;Number of Non-outliers:&amp;quot;, length(data_new_iqr)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Number of Non-outliers: 4970&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
data_new_iqr = [x for x in data if x &amp;gt;= lower_iqr and x &amp;lt;= upper_iqr]
print(&#39;Non-outlier observations: %d&#39; % len(data_new_iqr))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Non-outlier observations: 4965
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3. Xây dựng hàm tự động xác định và loại bỏ &lt;code&gt;outliers&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Chúng ta có thể tạo một hàm trên R dựa vào các bước ở trên để tự động xác định và xóa outliers như sau:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
# Tạo hàm tự động xác định và loại bỏ outliers bằng phương pháp STD
find_outliers_std &amp;lt;- function(data) {
  # tính giá trị biên Upper/Lower
  mean_data &amp;lt;- mean(data)
  std_data &amp;lt;- sd(data)
  limit = 3*std_data
  lower = mean_data - limit
  upper = mean_data + limit
  # xác định outliers
  ouliers_index &amp;lt;- which(data &amp;gt; upper | data &amp;lt; lower)
  # Thông báo thông tin về các outliers đã xóa
  if (length(ouliers_index) &amp;gt; 0 ) {
    message(paste(&amp;quot;Number of outliers:&amp;quot;, length(ouliers_index)))
    message(paste(&amp;quot;Number of Non-outliers:&amp;quot;, length(data_new_iqr)))
  # return the data with the outliers removed
  return(data[-ouliers_index])
  } else {
    message(&amp;quot;Not outliers&amp;quot;)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tương tự ta có thể tạo hàm xác định &lt;code&gt;outliers&lt;/code&gt; bằng phương pháp &lt;code&gt;IQR&lt;/code&gt; như sau:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Python
# Tạo hàm tự động xác định và loại bỏ outliers bằng phương pháp IQR
find_outliers_iqr &amp;lt;- function(data) {
  # Tính IQR
  q25 &amp;lt;- quantile(data)[2]
  q75 &amp;lt;- quantile(data)[4]
  iqr = q75 - q25 
  # Tính giá trị biên Upper/Lower để xác định outliers
  upper = q75 + iqr * 1.5
  lower = q25 - iqr * 1.5
  # xác định outliers
  ouliers_index &amp;lt;- which(data &amp;gt; upper | data &amp;lt; lower)
  # Thông báo thông tin về các outliers đã xóa
  if (length(ouliers_index) &amp;gt; 0 ) {
    message(paste(&amp;quot;Number of outliers:&amp;quot;, length(ouliers_index)))
    message(paste(&amp;quot;Number of Non-outliers:&amp;quot;, length(data_new_iqr)))
  # return the data with the outliers removed
  # return the data with the outliers removed
  return(data[-ouliers_index])
  } else {
    message(&amp;quot;Not outliers&amp;quot;)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kiểm tra kết quả thực hiện của hai hàm này:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;new_data_std &amp;lt;- find_outliers_std(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of outliers: 16
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of Non-outliers: 4970
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;new_data_iqr &amp;lt;- find_outliers_iqr(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of outliers: 30
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of Non-outliers: 4970
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Đối với Python thì các bạn có thể tạo hàm tương tự sử dụng các bước trên&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>The PdM Project</title>
      <link>/project/pdm-project/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/project/pdm-project/</guid>
      <description>&lt;p&gt;Sử dụng &lt;code&gt;R Shiny&lt;/code&gt; để phát triển ứng dụng &lt;code&gt;web&lt;/code&gt; tương tác (interactive web app), cho phép  &lt;code&gt;tracking&lt;/code&gt;   và   &lt;code&gt;visualization&lt;/code&gt;  luồng dữ liệu đa cảm biến, phát hiện bất thường, dự đoán hỏng hóc và tuổi thọ của máy móc trong thời gian thực.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/3Ir7xnPMX8o?autoplay=1&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
